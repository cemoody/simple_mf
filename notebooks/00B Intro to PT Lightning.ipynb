{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xE2B7ylXyWq"
   },
   "source": [
    "## Using PyTorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you've  written a dozen  pytorch models you'll discover that there's a lot of common structure and a huge amount of boilerplate. It's good to understand what's going on undere the hood, but when moving to production use cases you'll want to opt for more reliable, reproducible code. PyTorch Lightning & Ignite are great libraries that abstract away these core bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing `pytorch-lightning` requires tensorboard, which can have terrible conflicts. Good luck; here's the recipe that worked for me:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pip uninstall tensorboard\n",
    "    conda install tensorboard -y\n",
    "    conda install pytorch-lightning -y -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now install `wandb` which we'll use for logging & dashboarding of our models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a terminal also login to wandb by runing `wandb login`. You'll have to setup an account if you haven't before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28125, 9), (9375, 9), (12500, 9), (28125, 4), (9375, 4), (12500, 4))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "n = 50000\n",
    "# X is just a 9D normally distributed dataset\n",
    "X = np.random.normal(size=(n, 9)).astype(np.float32)\n",
    "# The prediction is a linear transformation on X\n",
    "# from 9D to 4D plus additive noise\n",
    "Y = np.random.normal(size=(n, 4)) * 1e-2 + np.dot(X, np.random.normal(size=(9, 4)))\n",
    "Y = Y.astype(np.float32)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "# Now split train into trai & validation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train)\n",
    "X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write an abstract model that defines training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write our initial model as Lightning  module:\n",
    "\n",
    "Don't be afraid of how much extra code this injects. Although it  initially looks like a ton of little class functions, it's all about being organized, deliberate, standardized and repeatable. It's not about science, it's about having good lab hygiene. \n",
    "\n",
    "- We'll move some of the iteration code into `training_step`  and `test_step`, and `test_epoch_end`.\n",
    "- Add in a `configure_optimizers` function.\n",
    "- Separate out train & test loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import from_numpy\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import BatchSampler\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "\n",
    "class MinimalAbstractModel(pl.LightningModule):\n",
    "    def __init(*args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        inpt, target = batch\n",
    "        prediction = self.forward(inpt)\n",
    "        loss = self.loss(prediction, target) + self.reg()\n",
    "        log = {f'train_loss': loss}\n",
    "        return {f'train_loss': loss, 'loss':loss, 'log': log}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write our specific model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we'll keep out `Bottleneck` model, but now it will inherit from our `AbstractModel`. Over the next few notebooks we'll keep using the `AbstractModel` class and just stick to focusing  our changes within the subclasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "\n",
    "\n",
    "class Bottleneck(MinimalAbstractModel):\n",
    "    def __init__(self, n_in_cols, n_out_cols, n_hidden=3, lam1=1e-3, lam2=1e-3):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(n_in_cols, n_hidden)\n",
    "        self.lin2 = nn.Linear(n_hidden, n_out_cols)\n",
    "        # Regularization coefficients\n",
    "        self.lam1 = lam1\n",
    "        self.lam2 = lam2\n",
    "        # this saves hyper parameters and they'll show up on W&B \n",
    "        # useful for when you inevtiably forget what they were, \n",
    "        # and then useful again for hyperparameter-tuning!\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x is a minibatch of rows of our features\n",
    "        hidden = self.lin1(x)\n",
    "        # y is a minibatch of our predictions\n",
    "        y = self.lin2(hidden)\n",
    "        return y\n",
    "\n",
    "    def loss(self, prediction, target):\n",
    "        # This is just the mean squared error\n",
    "        return ((prediction - target)**2.0).sum()\n",
    "    \n",
    "    def reg(self):\n",
    "        # This computes our Frobenius norm over both matrices\n",
    "        # Note that we can access the Linear model's variables\n",
    "        # directly if we'd like. No tricks here!\n",
    "        loss_reg_m1 = (self.lin1.weight**2.0 * self.lam1).sum()\n",
    "        loss_reg_m2 = (self.lin2.weight**2.0 * self.lam2).sum()\n",
    "        return loss_reg_m1 + loss_reg_m2\n",
    "\n",
    "\n",
    "model = Bottleneck(9, 4, 3)\n",
    "\n",
    "# add a logger\n",
    "logger = WandbLogger(name=\"00_intro\", log_model=True, project=\"simple_mf\")\n",
    "# logger = TensorBoardLogger(\"tb_logs\", name=\"bottleneck_model\")\n",
    "\n",
    "# We could have turned on multiple GPUs here, for example\n",
    "# trainer = pl.Trainer(gpus=8, precision=16)    \n",
    "trainer = pl.Trainer(max_epochs=3, progress_bar_refresh_rate=10, logger=logger)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit our model and then check the test loss again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = TensorDataset(from_numpy(X_train), from_numpy(Y_train))\n",
    "bs = BatchSampler(RandomSampler(dataset), \n",
    "                   batch_size=batch_size, drop_last=False)\n",
    "train = DataLoader(dataset, batch_sampler=bs, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish, PID 35807\n",
      "wandb: Program ended successfully.\n",
      "wandb:                                                                                \n",
      "wandb: Find user logs for this run at: wandb/run-20200918_083455-2he0evdd/logs/debug.log\n",
      "wandb: Find internal logs for this run at: wandb/run-20200918_083455-2he0evdd/logs/debug-internal.log\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: \n",
      "wandb: Synced 00_intro_optimize: https://app.wandb.ai/sf-moody/simple_mf/runs/2he0evdd\n",
      "wandb: Tracking run with wandb version 0.10.1\n",
      "wandb: Run data is saved locally in wandb/run-20200918_083633-12dluwai\n",
      "wandb: Syncing run 00_intro\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/sf-moody/simple_mf\" target=\"_blank\">https://app.wandb.ai/sf-moody/simple_mf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/sf-moody/simple_mf/runs/12dluwai\" target=\"_blank\">https://app.wandb.ai/sf-moody/simple_mf/runs/12dluwai</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | lin1 | Linear | 30    \n",
      "1 | lin2 | Linear | 16    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b06966d1aeb423cac8dac2c706d5aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! The test loss (~100) is much lower than it was before  ~4000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout the link on wandb to see train progress. For me, that link looks like (you'll get your own link, this one shouldn't work for you.)s: \n",
    "\n",
    "Run page: https://app.wandb.ai/chrisemoody/simple_mf-notebooks/runs/2o5ofsn4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in test & validation steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above `MinimalAbstractModel` is good for learning, but in practice we need to train on training data, continuously monitor  the validation dataset and stop early if it diverges, and then test the final score on test data. The abstract model class gets less legible, but conceptually there's not a lot that's new going on here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load abstract_model.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from torch import from_numpy\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import BatchSampler\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "\n",
    "class AbstractModel(pl.LightningModule):\n",
    "    def step(self, batch, batch_nb, prefix='train', add_reg=True):\n",
    "        input, target = batch\n",
    "        prediction = self.forward(input)\n",
    "        loss, log = self.loss(prediction, target)\n",
    "        \n",
    "        if add_reg:\n",
    "            loss_reg, log_ = self.reg()\n",
    "            loss = loss + loss_reg\n",
    "            log.update(log_)\n",
    "        log[f'{prefix}_loss'] = loss\n",
    "        return {f'{prefix}_loss': loss, 'loss':loss, 'log': log}\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        return self.step(batch, batch_nb, 'train')\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # Note that we do *not* include the regularization loss\n",
    "        # at test time\n",
    "        return self.step(batch, batch_nb, 'test', add_reg=False)    \n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        return self.step(batch, batch_nb, 'val', add_reg=False)    \n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        loss_mean = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        log = {'test_loss': loss_mean}\n",
    "        return {'avg_test_loss': loss_mean, 'log': log}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss_mean = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        log = {'val_loss': loss_mean}\n",
    "        return {'avg_val_loss': loss_mean, 'log': log}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's redefine the BottleNeck class, but this time inherting from `AbstractModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "\n",
    "\n",
    "class Bottleneck(AbstractModel):\n",
    "    def __init__(self, n_in_cols, n_out_cols, n_hidden=3, lam1=1e-3, lam2=1e-3):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(n_in_cols, n_hidden)\n",
    "        self.lin2 = nn.Linear(n_hidden, n_out_cols)\n",
    "        # Regularization coefficients\n",
    "        self.lam1 = lam1\n",
    "        self.lam2 = lam2\n",
    "        # this saves hyper parameters and they'll show up on W&B \n",
    "        # useful for when you inevtiably forget what they were, \n",
    "        # and then useful again for hyperparameter-tuning!\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x is a minibatch of rows of our features\n",
    "        hidden = self.lin1(x)\n",
    "        # y is a minibatch of our predictions\n",
    "        y = self.lin2(hidden)\n",
    "        return y\n",
    "\n",
    "    def loss(self, prediction, target):\n",
    "        # This is just the mean squared error\n",
    "        mse = ((prediction - target)**2.0).sum()\n",
    "        log = {'mse': mse}\n",
    "        return mse, log\n",
    "    \n",
    "    def reg(self):\n",
    "        # This computes our Frobenius norm over both matrices\n",
    "        # Note that we can access the Linear model's variables\n",
    "        # directly if we'd like. No tricks here!\n",
    "        loss_reg_m1 = (self.lin1.weight**2.0 * self.lam1).sum()\n",
    "        loss_reg_m2 = (self.lin2.weight**2.0 * self.lam2).sum()\n",
    "        log = {'loss_reg_m1': loss_reg_m1, 'loss_reg_m2': loss_reg_m2}\n",
    "        return loss_reg_m1 + loss_reg_m2, log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train the model, the parameters and weights will all be initialized randomly. So when we evaluate the test loss, it'll be pretty bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters with Optuna and Weights & Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have to instal optuna:\n",
    "    \n",
    "    pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(*arrs, batch_size=32):\n",
    "    dataset = TensorDataset(*arrs)\n",
    "    bs = BatchSampler(RandomSampler(dataset), \n",
    "                      batch_size=batch_size, drop_last=False)\n",
    "    return DataLoader(dataset, batch_sampler=bs, num_workers=8)\n",
    " \n",
    "train = dataloader(from_numpy(X_train), from_numpy(Y_train))\n",
    "test = dataloader(from_numpy(X_test), from_numpy(Y_test))\n",
    "val = dataloader(from_numpy(X_val), from_numpy(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Sample parameters -- without declaring them in advance!\n",
    "    n_hid = trial.suggest_int('n_hid', 1, 10)\n",
    "    lam1 = trial.suggest_loguniform('lam1', 1e-8, 1e-3)\n",
    "    lam2 = trial.suggest_loguniform('lam2', 1e-8, 1e-3)\n",
    "    \n",
    "    model = Bottleneck(9, 4, n_hid, lam1=lam1, lam2=lam2)\n",
    "    \n",
    "    logger = WandbLogger(name=\"00_intro_optimize\", log_model=True, project=\"simple_mf\")\n",
    "    logger.log_hyperparams(model.hparams)\n",
    "\n",
    "    # Note that we added early stoping  \n",
    "    trainer = pl.Trainer(max_epochs=3,\n",
    "                         early_stop_callback=True,\n",
    "                         logger=logger)    \n",
    "    trainer.fit(model, train, val)\n",
    "    test_results = trainer.test(model, test_dataloaders=[test])\n",
    "    test_loss = test_results['test_loss']\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-18 08:41:42,931] A new study created in memory with name: no-name-4b5586ff-dcbb-46d2-8416-88d80710da04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish, PID 37619\n",
      "wandb: Program ended successfully.\n",
      "wandb:                                                                                \n",
      "wandb: Find user logs for this run at: wandb/run-20200918_084002-2snostrd/logs/debug.log\n",
      "wandb: Find internal logs for this run at: wandb/run-20200918_084002-2snostrd/logs/debug-internal.log\n",
      "wandb: Run summary:\n",
      "wandb:   global_step 2637\n",
      "wandb:           mse 0.014328286983072758\n",
      "wandb:   loss_reg_m1 8.590106517658569e-06\n",
      "wandb:   loss_reg_m2 0.0054049198515713215\n",
      "wandb:    train_loss 0.01974179595708847\n",
      "wandb:         epoch 2\n",
      "wandb:         _step 54\n",
      "wandb:      _runtime 10\n",
      "wandb:    _timestamp 1600443616\n",
      "wandb:      val_loss 0.012885155156254768\n",
      "wandb:     test_loss 0.01287017296999693\n",
      "wandb: Run history:\n",
      "wandb:   global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
      "wandb:           mse ██▆▆▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "wandb:   loss_reg_m1 ▁▁▂▂▄▄▅▆▇▇▇█████████████████████████████\n",
      "wandb:   loss_reg_m2 ▁▁▂▂▄▄▅▆▇▇▇█████████████████████████████\n",
      "wandb:    train_loss ██▆▆▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "wandb:         epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅██████████████\n",
      "wandb:         _step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
      "wandb:      _runtime ▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇█\n",
      "wandb:    _timestamp ▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇█\n",
      "wandb:      val_loss █▁▁\n",
      "wandb:     test_loss ▁\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "wandb: \n",
      "wandb: Synced 00_intro_optimize: https://app.wandb.ai/sf-moody/simple_mf/runs/2snostrd\n",
      "wandb: Tracking run with wandb version 0.10.1\n",
      "wandb: Run data is saved locally in wandb/run-20200918_084142-2sze3snq\n",
      "wandb: Syncing run 00_intro_optimize\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/sf-moody/simple_mf\" target=\"_blank\">https://app.wandb.ai/sf-moody/simple_mf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/sf-moody/simple_mf/runs/2sze3snq\" target=\"_blank\">https://app.wandb.ai/sf-moody/simple_mf/runs/2sze3snq</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | lin1 | Linear | 50    \n",
      "1 | lin2 | Linear | 24    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7c66da0f8348bf84b230591180969b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1168ecf4ac064c12ab5204ce73b8fb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_loss': tensor(0.0129), 'test_loss': tensor(0.0129)}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-18 08:41:56,631] Trial 0 finished with value: 0.012920357286930084 and parameters: {'n_hid': 5, 'lam1': 7.092391053893507e-05, 'lam2': 1.629230674510399e-07}. Best is trial 0 with value: 0.012920357286930084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish, PID 38225\n",
      "wandb: Program ended successfully.\n",
      "wandb:                                                                                \n",
      "wandb: Find user logs for this run at: wandb/run-20200918_084142-2sze3snq/logs/debug.log\n",
      "wandb: Find internal logs for this run at: wandb/run-20200918_084142-2sze3snq/logs/debug-internal.log\n",
      "wandb: Run summary:\n",
      "wandb:   global_step 2637\n",
      "wandb:           mse 0.011638514697551727\n",
      "wandb:   loss_reg_m1 0.0008876376668922603\n",
      "wandb:   loss_reg_m2 1.804168618946278e-06\n",
      "wandb:    train_loss 0.012527956627309322\n",
      "wandb:         epoch 2\n",
      "wandb:         _step 54\n",
      "wandb:      _runtime 10\n",
      "wandb:    _timestamp 1600443716\n",
      "wandb:      val_loss 0.012905266135931015\n",
      "wandb:     test_loss 0.012920357286930084\n",
      "wandb: Run history:\n",
      "wandb:   global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
      "wandb:           mse ▇█▇▇▅▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "wandb:   loss_reg_m1 ▁▁▁▁▂▃▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████████\n",
      "wandb:   loss_reg_m2 ▁▁▁▂▂▃▄▄▅▆▆▆▇▇▇▇▇▇▇▇▇███████████████████\n",
      "wandb:    train_loss ▇█▇▇▅▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "wandb:         epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅██████████████\n",
      "wandb:         _step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
      "wandb:      _runtime ▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇█\n",
      "wandb:    _timestamp ▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇█\n",
      "wandb:      val_loss █▁▁\n",
      "wandb:     test_loss ▁\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "wandb: \n",
      "wandb: Synced 00_intro_optimize: https://app.wandb.ai/sf-moody/simple_mf/runs/2sze3snq\n",
      "wandb: Tracking run with wandb version 0.10.1\n",
      "wandb: Run data is saved locally in wandb/run-20200918_084156-2hbtrug1\n",
      "wandb: Syncing run 00_intro_optimize\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/sf-moody/simple_mf\" target=\"_blank\">https://app.wandb.ai/sf-moody/simple_mf</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/sf-moody/simple_mf/runs/2hbtrug1\" target=\"_blank\">https://app.wandb.ai/sf-moody/simple_mf/runs/2hbtrug1</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | lin1 | Linear | 10    \n",
      "1 | lin2 | Linear | 8     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62057024a9a423eb92799ea7e3f243b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophermoody/.virtualenvs/py36/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd40b4d75ed4857a600d2fa37a141bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_loss': tensor(594.6829), 'test_loss': tensor(594.6829)}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-18 08:42:08,085] Trial 1 finished with value: 594.6829223632812 and parameters: {'n_hid': 1, 'lam1': 1.4346912298673874e-06, 'lam2': 0.000301701653594169}. Best is trial 0 with value: 0.012920357286930084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish, PID 38405\n",
      "wandb: Program ended successfully.\n",
      "wandb: ERROR Control-C detected -- Run data was not synced\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "00 Intro PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
