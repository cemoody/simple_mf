{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "08 Mixture of Tastes.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1wzSgfGhe8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "856d260f-effc-457d-897e-33ea68cb5e2a"
      },
      "source": [
        "!rm -rdf loader* data/* data* ../data ../data*\n",
        "!wget https://raw.githubusercontent.com/cemoody/simple_mf/master/notebooks/loader.py\n",
        "!mkdir ../data\n",
        "!wget https://www.dropbox.com/s/msqzmmaog5bstm4/dataset.npz?dl=0\n",
        "!mv dataset.npz?dl=0 ../data/dataset.npz\n",
        "!pip install pytorch-ignite tensorboardX"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-18 17:18:42--  https://raw.githubusercontent.com/cemoody/simple_mf/master/notebooks/loader.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1014 [text/plain]\n",
            "Saving to: ‘loader.py’\n",
            "\n",
            "\rloader.py             0%[                    ]       0  --.-KB/s               \rloader.py           100%[===================>]    1014  --.-KB/s    in 0s      \n",
            "\n",
            "2019-11-18 17:18:42 (156 MB/s) - ‘loader.py’ saved [1014/1014]\n",
            "\n",
            "--2019-11-18 17:18:44--  https://www.dropbox.com/s/msqzmmaog5bstm4/dataset.npz?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/msqzmmaog5bstm4/dataset.npz [following]\n",
            "--2019-11-18 17:18:44--  https://www.dropbox.com/s/raw/msqzmmaog5bstm4/dataset.npz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucacee8f0ba6b6c9624dd31d4263.dl.dropboxusercontent.com/cd/0/inline/AsnKfmI3W2SVcNZgp-_V8VJzSqWyq4dnDzTGnkzdRytL3sldxI8MzdQNpPF-dFFkAjGgJXo1h6OvrbZpdMRtCjCyYOq6StojwlEfq7ZH3JNwGA/file# [following]\n",
            "--2019-11-18 17:18:44--  https://ucacee8f0ba6b6c9624dd31d4263.dl.dropboxusercontent.com/cd/0/inline/AsnKfmI3W2SVcNZgp-_V8VJzSqWyq4dnDzTGnkzdRytL3sldxI8MzdQNpPF-dFFkAjGgJXo1h6OvrbZpdMRtCjCyYOq6StojwlEfq7ZH3JNwGA/file\n",
            "Resolving ucacee8f0ba6b6c9624dd31d4263.dl.dropboxusercontent.com (ucacee8f0ba6b6c9624dd31d4263.dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:6016:6::a27d:106\n",
            "Connecting to ucacee8f0ba6b6c9624dd31d4263.dl.dropboxusercontent.com (ucacee8f0ba6b6c9624dd31d4263.dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AskErSx4FzbpSkUf9VoXP5EVteuF7J8GqE-3Gg6xfDusvladfx7eINSyzPGuDb4EWBUOsIAy_QCewyqght06LrG1SrVH4177-V48xwGWrdhAFnL7VdsHS35I1RxhxnDW6zlInBA0GRvtbdhXFwAC4mBn8imosvxsvqmSCQe307UjVqBqar9BnqHNvZqBew_vupGBMgbKg6RfwYqT7eZBQEs3BTWUcIK4_5X31qn0YkuF4L7KokCSD1nWie89_xNmyz7uUW9GWOB_E8rpocuVSj_Ng0eqBFLdRYNIIeDZ0amCplcNKgzndmX4UYzhVkI70NzImx8oJTNv67gxVosax0Yg/file [following]\n",
            "--2019-11-18 17:18:45--  https://ucacee8f0ba6b6c9624dd31d4263.dl.dropboxusercontent.com/cd/0/inline2/AskErSx4FzbpSkUf9VoXP5EVteuF7J8GqE-3Gg6xfDusvladfx7eINSyzPGuDb4EWBUOsIAy_QCewyqght06LrG1SrVH4177-V48xwGWrdhAFnL7VdsHS35I1RxhxnDW6zlInBA0GRvtbdhXFwAC4mBn8imosvxsvqmSCQe307UjVqBqar9BnqHNvZqBew_vupGBMgbKg6RfwYqT7eZBQEs3BTWUcIK4_5X31qn0YkuF4L7KokCSD1nWie89_xNmyz7uUW9GWOB_E8rpocuVSj_Ng0eqBFLdRYNIIeDZ0amCplcNKgzndmX4UYzhVkI70NzImx8oJTNv67gxVosax0Yg/file\n",
            "Reusing existing connection to ucacee8f0ba6b6c9624dd31d4263.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60015046 (57M) [application/octet-stream]\n",
            "Saving to: ‘dataset.npz?dl=0’\n",
            "\n",
            "dataset.npz?dl=0    100%[===================>]  57.23M  7.65MB/s    in 7.9s    \n",
            "\n",
            "2019-11-18 17:18:53 (7.28 MB/s) - ‘dataset.npz?dl=0’ saved [60015046/60015046]\n",
            "\n",
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/31/efcc2b587419b1f54c5c6ef51996f91bb5d8f760537d17de674c89e06048/pytorch_ignite-0.2.1-py2.py3-none-any.whl (84kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.1MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/5c/e918d9f190baab8d55bad52840d8091dd5114cc99f03eaa6d72d404503cc/tensorboardX-1.9-py2.py3-none-any.whl (190kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 14.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.3.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (41.6.0)\n",
            "Installing collected packages: pytorch-ignite, tensorboardX\n",
            "Successfully installed pytorch-ignite-0.2.1 tensorboardX-1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKwpNrBXhdCI",
        "colab_type": "text"
      },
      "source": [
        "### Load preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsQ5KuqIhdCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "fh = np.load('../data/dataset.npz')\n",
        "# We have a bunch of feature columns and last column is the y-target\n",
        "train_x = fh['train_x'].astype(np.int64)\n",
        "train_y = fh['train_y']\n",
        "\n",
        "test_x = fh['test_x'].astype(np.int64)\n",
        "test_y = fh['test_y']\n",
        "\n",
        "n_user = int(fh['n_user'])\n",
        "n_item = int(fh['n_item'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDtTys9hhdCN",
        "colab_type": "text"
      },
      "source": [
        "### Define the MF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZckAa_1hdCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def l2_regularize(array):\n",
        "    loss = torch.sum(array ** 2.0)\n",
        "    return loss\n",
        "\n",
        "\n",
        "class MF(nn.Module):\n",
        "    itr = 0\n",
        "    \n",
        "    def __init__(self, n_user, n_item, k=18, c=4,\n",
        "                 c_vector=1.0, c_bias=1.0, writer=None):\n",
        "        super(MF, self).__init__()\n",
        "        self.writer = writer\n",
        "        self.k = k\n",
        "        self.n_user = n_user\n",
        "        self.n_item = n_item\n",
        "        self.c_bias = c_bias\n",
        "        self.c_vector = c_vector\n",
        "        \n",
        "        self.bias_user = nn.Embedding(n_user, 1)\n",
        "        self.bias_item = nn.Embedding(n_item, 1)\n",
        "        self.bias = nn.Parameter(torch.ones(1))\n",
        "        self.item = nn.Embedding(n_item, k)\n",
        "        \n",
        "        # **NEW: user taste & attention vectors\n",
        "        user_taste = torch.zeros(n_user, k, c)\n",
        "        user_attnd = torch.zeros(n_user, k, c)\n",
        "        user_taste.data.normal_(0, 1.0 / n_user)\n",
        "        user_attnd.data.normal_(0, 1.0 / n_user)\n",
        "        \n",
        "        self.user_taste = nn.Parameter(user_taste)\n",
        "        self.user_attnd = nn.Parameter(user_attnd)\n",
        "\n",
        "    \n",
        "    def __call__(self, train_x):\n",
        "        user_id = train_x[:, 0]\n",
        "        item_id = train_x[:, 1]\n",
        "        vector_item = self.item(item_id)\n",
        "        bias_user = self.bias_user(user_id).squeeze()\n",
        "        bias_item = self.bias_item(item_id).squeeze()\n",
        "        biases = (self.bias + bias_user + bias_item)\n",
        "        \n",
        "        # **NEW: user taste & attention\n",
        "        user_taste = self.user_taste[user_id]\n",
        "        user_attnd = self.user_attnd[user_id]\n",
        "        vector_itemx = vector_item.unsqueeze(2).expand_as(user_attnd)\n",
        "        attention = F.softmax(user_attnd * vector_itemx, dim=1)\n",
        "        attentionx = attention.sum(2).unsqueeze(2).expand_as(user_attnd)\n",
        "        weighted_preference = (user_taste * attentionx).sum(2)\n",
        "        dot = (weighted_preference * vector_item).sum(1)\n",
        "        \n",
        "        prediction = dot + biases\n",
        "        return prediction\n",
        "    \n",
        "    def loss(self, prediction, target):\n",
        "        loss_mse = F.mse_loss(prediction.squeeze(), target.squeeze())\n",
        "        prior_bias_user =  l2_regularize(self.bias_user.weight) * self.c_bias\n",
        "        prior_bias_item = l2_regularize(self.bias_item.weight) * self.c_bias\n",
        "        prior_taste =  l2_regularize(self.user_taste) * self.c_vector\n",
        "        prior_attnd =  l2_regularize(self.user_attnd) * self.c_vector\n",
        "        prior_item = l2_regularize(self.item.weight) * self.c_vector\n",
        "        \n",
        "        total = (loss_mse + prior_bias_item + prior_bias_user +\n",
        "                 prior_taste + prior_attnd + prior_item)\n",
        "        for name, var in locals().items():\n",
        "            if type(var) is torch.Tensor and var.nelement() == 1 and self.writer is not None:\n",
        "                self.writer.add_scalar(name, var, self.itr)\n",
        "        return total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O2WuYqihdCQ",
        "colab_type": "text"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhTMUDqFhdCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Loss\n",
        "from tensorboardX import SummaryWriter\n",
        "from ignite.metrics import MeanSquaredError\n",
        "\n",
        "from loader import Loader\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gki4og-hdCU",
        "colab_type": "text"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTrV3kVThdCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6036e29-6bab-4e2e-c1c4-e1fabfa662d4"
      },
      "source": [
        "lr = 1e-2\n",
        "k = 16\n",
        "c = 4\n",
        "c_bias = 1e-6\n",
        "c_vector = 1e-6\n",
        "\n",
        "log_dir = 'runs/simple_mf_07_mot_' + str(datetime.now()).replace(' ', '_')\n",
        "print(log_dir)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "runs/simple_mf_07_mot_2019-11-18_17:19:22.639971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2G2XaSihdCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fef5b43f-cc10-44ba-a445-cc2f26254fd5"
      },
      "source": [
        "writer = SummaryWriter(log_dir=log_dir)\n",
        "model = MF(n_user, n_item,  k=k, c=c, c_bias=c_bias, \n",
        "           c_vector=c_vector, writer=writer)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "trainer = create_supervised_trainer(model, optimizer, model.loss)\n",
        "metrics = {'accuracy': MeanSquaredError()}\n",
        "evaluat = create_supervised_evaluator(model, metrics=metrics)\n",
        "train_loader = Loader(train_x, train_y, batchsize=1024)\n",
        "test_loader = Loader(test_x, test_y, batchsize=1024)\n",
        "\n",
        "\n",
        "def log_training_loss(engine, log_interval=400):\n",
        "    epoch = engine.state.epoch\n",
        "    itr = engine.state.iteration\n",
        "    fmt = \"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
        "    msg = fmt.format(epoch, itr, len(train_loader), engine.state.output)\n",
        "    model.itr = itr\n",
        "    if itr % log_interval == 0:\n",
        "        print(msg)\n",
        "\n",
        "trainer.add_event_handler(event_name=Events.ITERATION_COMPLETED, handler=log_training_loss)\n",
        "\n",
        "def log_validation_results(engine):\n",
        "    evaluat.run(test_loader)\n",
        "    metrics = evaluat.state.metrics\n",
        "    avg_accuracy = metrics['accuracy']\n",
        "    print(\"Epoch[{}] Validation MSE: {:.2f} \"\n",
        "          .format(engine.state.epoch, avg_accuracy))\n",
        "    writer.add_scalar(\"validation/avg_accuracy\", avg_accuracy, engine.state.epoch)\n",
        "\n",
        "trainer.add_event_handler(event_name=Events.EPOCH_COMPLETED, handler=log_validation_results)\n",
        "model"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MF(\n",
              "  (bias_user): Embedding(6041, 1)\n",
              "  (bias_item): Embedding(3953, 1)\n",
              "  (item): Embedding(3953, 16)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RujM9528hdCc",
        "colab_type": "text"
      },
      "source": [
        "#### Run model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbuEwp0XhdCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1dd60445-0cfe-4897-a85c-0573c10be1a0"
      },
      "source": [
        "trainer.run(train_loader, max_epochs=250)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch[1] Iteration[400/879] Loss: 1.34\n",
            "Epoch[1] Iteration[800/879] Loss: 1.08\n",
            "Epoch[1] Validation MSE: 1.00 \n",
            "Epoch[2] Iteration[1200/879] Loss: 0.86\n",
            "Epoch[2] Iteration[1600/879] Loss: 0.90\n",
            "Epoch[2] Validation MSE: 0.90 \n",
            "Epoch[3] Iteration[2000/879] Loss: 0.86\n",
            "Epoch[3] Iteration[2400/879] Loss: 0.82\n",
            "Epoch[3] Validation MSE: 0.85 \n",
            "Epoch[4] Iteration[2800/879] Loss: 0.71\n",
            "Epoch[4] Iteration[3200/879] Loss: 0.79\n",
            "Epoch[4] Validation MSE: 0.82 \n",
            "Epoch[5] Iteration[3600/879] Loss: 0.63\n",
            "Epoch[5] Iteration[4000/879] Loss: 0.70\n",
            "Epoch[5] Validation MSE: 0.81 \n",
            "Epoch[6] Iteration[4400/879] Loss: 0.63\n",
            "Epoch[6] Iteration[4800/879] Loss: 0.71\n",
            "Epoch[6] Iteration[5200/879] Loss: 0.73\n",
            "Epoch[6] Validation MSE: 0.80 \n",
            "Epoch[7] Iteration[5600/879] Loss: 0.68\n",
            "Epoch[7] Iteration[6000/879] Loss: 0.67\n",
            "Epoch[7] Validation MSE: 0.79 \n",
            "Epoch[8] Iteration[6400/879] Loss: 0.65\n",
            "Epoch[8] Iteration[6800/879] Loss: 0.74\n",
            "Epoch[8] Validation MSE: 0.79 \n",
            "Epoch[9] Iteration[7200/879] Loss: 0.66\n",
            "Epoch[9] Iteration[7600/879] Loss: 0.72\n",
            "Epoch[9] Validation MSE: 0.79 \n",
            "Epoch[10] Iteration[8000/879] Loss: 0.67\n",
            "Epoch[10] Iteration[8400/879] Loss: 0.68\n",
            "Epoch[10] Validation MSE: 0.78 \n",
            "Epoch[11] Iteration[8800/879] Loss: 0.59\n",
            "Epoch[11] Iteration[9200/879] Loss: 0.73\n",
            "Epoch[11] Iteration[9600/879] Loss: 0.72\n",
            "Epoch[11] Validation MSE: 0.79 \n",
            "Epoch[12] Iteration[10000/879] Loss: 0.71\n",
            "Epoch[12] Iteration[10400/879] Loss: 0.77\n",
            "Epoch[12] Validation MSE: 0.78 \n",
            "Epoch[13] Iteration[10800/879] Loss: 0.70\n",
            "Epoch[13] Iteration[11200/879] Loss: 0.78\n",
            "Epoch[13] Validation MSE: 0.78 \n",
            "Epoch[14] Iteration[11600/879] Loss: 0.64\n",
            "Epoch[14] Iteration[12000/879] Loss: 0.71\n",
            "Epoch[14] Validation MSE: 0.78 \n",
            "Epoch[15] Iteration[12400/879] Loss: 0.63\n",
            "Epoch[15] Iteration[12800/879] Loss: 0.71\n",
            "Epoch[15] Validation MSE: 0.78 \n",
            "Epoch[16] Iteration[13200/879] Loss: 0.61\n",
            "Epoch[16] Iteration[13600/879] Loss: 0.67\n",
            "Epoch[16] Iteration[14000/879] Loss: 0.69\n",
            "Epoch[16] Validation MSE: 0.78 \n",
            "Epoch[17] Iteration[14400/879] Loss: 0.72\n",
            "Epoch[17] Iteration[14800/879] Loss: 0.71\n",
            "Epoch[17] Validation MSE: 0.78 \n",
            "Epoch[18] Iteration[15200/879] Loss: 0.72\n",
            "Epoch[18] Iteration[15600/879] Loss: 0.74\n",
            "Epoch[18] Validation MSE: 0.78 \n",
            "Epoch[19] Iteration[16000/879] Loss: 0.66\n",
            "Epoch[19] Iteration[16400/879] Loss: 0.70\n",
            "Epoch[19] Validation MSE: 0.78 \n",
            "Epoch[20] Iteration[16800/879] Loss: 0.64\n",
            "Epoch[20] Iteration[17200/879] Loss: 0.73\n",
            "Epoch[20] Validation MSE: 0.78 \n",
            "Epoch[21] Iteration[17600/879] Loss: 0.59\n",
            "Epoch[21] Iteration[18000/879] Loss: 0.68\n",
            "Epoch[21] Iteration[18400/879] Loss: 0.70\n",
            "Epoch[21] Validation MSE: 0.78 \n",
            "Epoch[22] Iteration[18800/879] Loss: 0.68\n",
            "Epoch[22] Iteration[19200/879] Loss: 0.66\n",
            "Epoch[22] Validation MSE: 0.78 \n",
            "Epoch[23] Iteration[19600/879] Loss: 0.64\n",
            "Epoch[23] Iteration[20000/879] Loss: 0.65\n",
            "Epoch[23] Validation MSE: 0.78 \n",
            "Epoch[24] Iteration[20400/879] Loss: 0.66\n",
            "Epoch[24] Iteration[20800/879] Loss: 0.66\n",
            "Epoch[24] Validation MSE: 0.78 \n",
            "Epoch[25] Iteration[21200/879] Loss: 0.65\n",
            "Epoch[25] Iteration[21600/879] Loss: 0.69\n",
            "Epoch[25] Validation MSE: 0.78 \n",
            "Epoch[26] Iteration[22000/879] Loss: 0.62\n",
            "Epoch[26] Iteration[22400/879] Loss: 0.65\n",
            "Epoch[26] Iteration[22800/879] Loss: 0.78\n",
            "Epoch[26] Validation MSE: 0.78 \n",
            "Epoch[27] Iteration[23200/879] Loss: 0.67\n",
            "Epoch[27] Iteration[23600/879] Loss: 0.72\n",
            "Epoch[27] Validation MSE: 0.78 \n",
            "Epoch[28] Iteration[24000/879] Loss: 0.64\n",
            "Epoch[28] Iteration[24400/879] Loss: 0.68\n",
            "Epoch[28] Validation MSE: 0.78 \n",
            "Epoch[29] Iteration[24800/879] Loss: 0.66\n",
            "Epoch[29] Iteration[25200/879] Loss: 0.73\n",
            "Epoch[29] Validation MSE: 0.78 \n",
            "Epoch[30] Iteration[25600/879] Loss: 0.65\n",
            "Epoch[30] Iteration[26000/879] Loss: 0.73\n",
            "Epoch[30] Validation MSE: 0.78 \n",
            "Epoch[31] Iteration[26400/879] Loss: 0.60\n",
            "Epoch[31] Iteration[26800/879] Loss: 0.66\n",
            "Epoch[31] Iteration[27200/879] Loss: 0.77\n",
            "Epoch[31] Validation MSE: 0.78 \n",
            "Epoch[32] Iteration[27600/879] Loss: 0.71\n",
            "Epoch[32] Iteration[28000/879] Loss: 0.69\n",
            "Epoch[32] Validation MSE: 0.78 \n",
            "Epoch[33] Iteration[28400/879] Loss: 0.70\n",
            "Epoch[33] Iteration[28800/879] Loss: 0.78\n",
            "Epoch[33] Validation MSE: 0.78 \n",
            "Epoch[34] Iteration[29200/879] Loss: 0.66\n",
            "Epoch[34] Iteration[29600/879] Loss: 0.70\n",
            "Epoch[34] Validation MSE: 0.78 \n",
            "Epoch[35] Iteration[30000/879] Loss: 0.65\n",
            "Epoch[35] Iteration[30400/879] Loss: 0.70\n",
            "Epoch[35] Validation MSE: 0.78 \n",
            "Epoch[36] Iteration[30800/879] Loss: 0.63\n",
            "Epoch[36] Iteration[31200/879] Loss: 0.74\n",
            "Epoch[36] Iteration[31600/879] Loss: 0.68\n",
            "Epoch[36] Validation MSE: 0.78 \n",
            "Epoch[37] Iteration[32000/879] Loss: 0.66\n",
            "Epoch[37] Iteration[32400/879] Loss: 0.65\n",
            "Epoch[37] Validation MSE: 0.78 \n",
            "Epoch[38] Iteration[32800/879] Loss: 0.73\n",
            "Epoch[38] Iteration[33200/879] Loss: 0.70\n",
            "Epoch[38] Validation MSE: 0.78 \n",
            "Epoch[39] Iteration[33600/879] Loss: 0.68\n",
            "Epoch[39] Iteration[34000/879] Loss: 0.72\n",
            "Epoch[39] Validation MSE: 0.78 \n",
            "Epoch[40] Iteration[34400/879] Loss: 0.62\n",
            "Epoch[40] Iteration[34800/879] Loss: 0.68\n",
            "Epoch[40] Validation MSE: 0.78 \n",
            "Epoch[41] Iteration[35200/879] Loss: 0.60\n",
            "Epoch[41] Iteration[35600/879] Loss: 0.70\n",
            "Epoch[41] Iteration[36000/879] Loss: 0.69\n",
            "Epoch[41] Validation MSE: 0.78 \n",
            "Epoch[42] Iteration[36400/879] Loss: 0.68\n",
            "Epoch[42] Iteration[36800/879] Loss: 0.75\n",
            "Epoch[42] Validation MSE: 0.78 \n",
            "Epoch[43] Iteration[37200/879] Loss: 0.66\n",
            "Epoch[43] Iteration[37600/879] Loss: 0.71\n",
            "Epoch[43] Validation MSE: 0.78 \n",
            "Epoch[44] Iteration[38000/879] Loss: 0.64\n",
            "Epoch[44] Iteration[38400/879] Loss: 0.71\n",
            "Epoch[44] Validation MSE: 0.78 \n",
            "Epoch[45] Iteration[38800/879] Loss: 0.66\n",
            "Epoch[45] Iteration[39200/879] Loss: 0.67\n",
            "Epoch[45] Validation MSE: 0.78 \n",
            "Epoch[46] Iteration[39600/879] Loss: 0.58\n",
            "Epoch[46] Iteration[40000/879] Loss: 0.67\n",
            "Epoch[46] Iteration[40400/879] Loss: 0.74\n",
            "Epoch[46] Validation MSE: 0.78 \n",
            "Epoch[47] Iteration[40800/879] Loss: 0.67\n",
            "Epoch[47] Iteration[41200/879] Loss: 0.67\n",
            "Epoch[47] Validation MSE: 0.78 \n",
            "Epoch[48] Iteration[41600/879] Loss: 0.64\n",
            "Epoch[48] Iteration[42000/879] Loss: 0.71\n",
            "Epoch[48] Validation MSE: 0.78 \n",
            "Epoch[49] Iteration[42400/879] Loss: 0.70\n",
            "Epoch[49] Iteration[42800/879] Loss: 0.69\n",
            "Epoch[49] Validation MSE: 0.78 \n",
            "Epoch[50] Iteration[43200/879] Loss: 0.66\n",
            "Epoch[50] Iteration[43600/879] Loss: 0.73\n",
            "Epoch[50] Validation MSE: 0.78 \n",
            "Epoch[51] Iteration[44000/879] Loss: 0.55\n",
            "Epoch[51] Iteration[44400/879] Loss: 0.71\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}