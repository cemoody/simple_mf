{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "05 Simple MF Biases is actually word2vec.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIxp6FWocPfa",
        "colab_type": "text"
      },
      "source": [
        "### Load preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1TiVdQwgWOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "7ec041cb-7c28-47e9-c3de-bcb0db5899b3"
      },
      "source": [
        "!pip install pytorch-ignite tensorboardX\n",
        "!wget https://raw.githubusercontent.com/cemoody/simple_mf/master/notebooks/loader.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (1.9)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.3.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (41.6.0)\n",
            "--2019-11-18 17:14:01--  https://raw.githubusercontent.com/cemoody/simple_mf/master/notebooks/loader.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1014 [text/plain]\n",
            "Saving to: ‘loader.py’\n",
            "\n",
            "loader.py           100%[===================>]    1014  --.-KB/s    in 0s      \n",
            "\n",
            "2019-11-18 17:14:02 (210 MB/s) - ‘loader.py’ saved [1014/1014]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQChQX4gcTPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "6ad170e8-48d9-4514-f0d4-174304e7c025"
      },
      "source": [
        "!wget https://www.dropbox.com/s/nd1zxh538o6psal/skipgram_full.npz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-18 16:56:06--  https://www.dropbox.com/s/nd1zxh538o6psal/skipgram_full.npz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/nd1zxh538o6psal/skipgram_full.npz [following]\n",
            "--2019-11-18 16:56:07--  https://www.dropbox.com/s/raw/nd1zxh538o6psal/skipgram_full.npz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com/cd/0/inline/AsmCMf93WirnSmlkzuHxQU9OZaut_5lNSJmuaLVWNkpIv7Jvhj0xvCcbpGI0ToG7EY76LroIZpy9Ro62uhgwD7tWglNGA3WSHZjlL_KzGf-FMQ/file# [following]\n",
            "--2019-11-18 16:56:07--  https://uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com/cd/0/inline/AsmCMf93WirnSmlkzuHxQU9OZaut_5lNSJmuaLVWNkpIv7Jvhj0xvCcbpGI0ToG7EY76LroIZpy9Ro62uhgwD7tWglNGA3WSHZjlL_KzGf-FMQ/file\n",
            "Resolving uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com (uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com (uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/Asl5bUKLiLagUBYFzf8fU7dO8PT2aEAZWbn5q2_Xwc78lQchIDHYLp_epJMsyzh9nyAbZa0BAeu-OHKe4ch35mwbRhPYO4XnhEARmAQ7ycXi2WWQ74-qqZRow4_VU7lyDV2t3egM1q7uPunGJQ2Gv0ApfgCQ3-5thrAaWLGaL7cSBeLCxFU0I-EWd4UXW9wOuifMWj-t_U7SHFerhUumw0c60f4tUi2hXN3knZHuKdgGiZJlHaqT6xZr4pSGfwUG_f_plMna6BabJPWCONoAbpq3LPkl5RulmU2JhavJdxUOMnb37eGefT6mWKJtEcOUTHI4V1By_5mJtsjTe_Z5_Gld/file [following]\n",
            "--2019-11-18 16:56:08--  https://uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com/cd/0/inline2/Asl5bUKLiLagUBYFzf8fU7dO8PT2aEAZWbn5q2_Xwc78lQchIDHYLp_epJMsyzh9nyAbZa0BAeu-OHKe4ch35mwbRhPYO4XnhEARmAQ7ycXi2WWQ74-qqZRow4_VU7lyDV2t3egM1q7uPunGJQ2Gv0ApfgCQ3-5thrAaWLGaL7cSBeLCxFU0I-EWd4UXW9wOuifMWj-t_U7SHFerhUumw0c60f4tUi2hXN3knZHuKdgGiZJlHaqT6xZr4pSGfwUG_f_plMna6BabJPWCONoAbpq3LPkl5RulmU2JhavJdxUOMnb37eGefT6mWKJtEcOUTHI4V1By_5mJtsjTe_Z5_Gld/file\n",
            "Reusing existing connection to uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 987227756 (941M) [application/octet-stream]\n",
            "Saving to: ‘skipgram_full.npz’\n",
            "\n",
            "skipgram_full.npz   100%[===================>] 941.49M  48.1MB/s    in 7m 5s   \n",
            "\n",
            "2019-11-18 17:03:13 (2.22 MB/s) - ‘skipgram_full.npz’ saved [987227756/987227756]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQETdenXcPfc",
        "colab_type": "text"
      },
      "source": [
        "If you'd like to play around with this notebook, start by downloading the skipgram dataset from here:\n",
        "\n",
        "https://www.dropbox.com/s/nd1zxh538o6psal/skipgram_full.npz\n",
        "\n",
        "WARNING: it's a 1Gb download, so it may take a while!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2ULzzpecPfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "codes = np.load(\"skipgram_full.npz\")['coded']\n",
        "# Remove duplicate skipgrams\n",
        "codes = codes[codes[:, 0] != codes[:, 1]]\n",
        "code2token = np.load(\"skipgram_full.npz\", allow_pickle=True)['c2t'].tolist()\n",
        "token2code = np.load(\"skipgram_full.npz\", allow_pickle=True)['t2c'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dpA_eiMcPfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "666d7d9a-9789-4706-bb61-2430911e15f3"
      },
      "source": [
        "# First column is the first token code\n",
        "# second column is the 2nd token code\n",
        "# third column is the skip gram count\n",
        "# fourth is PMI * 1e6\n",
        "codes"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  13835,    3257,    4605,  592814],\n",
              "       [  12071,    3257,      16,  491071],\n",
              "       [   4136,    3257,       2, -621270],\n",
              "       ...,\n",
              "       [  12293,    1390,       1, 1092727],\n",
              "       [   5103,    1390,       1, 2368132],\n",
              "       [   6789,    1390,       1,  427689]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAXh1bfQcPfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "62277727-6add-4219-f0b7-a160576b74e9"
      },
      "source": [
        "train_x = codes[:, :2].copy().astype(np.int64)\n",
        "train_y = codes[:, 3].astype(np.float32) / 1e6\n",
        "train_y"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.592814,  0.491071, -0.62127 , ...,  1.092727,  2.368132,\n",
              "        0.427689], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOGuDRkzcPfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f815d303-9d70-4a00-8f79-5ae9d8a04834"
      },
      "source": [
        "train_y.max()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.09618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCV2ioOhcPfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3ad02e4b-19ca-49f7-ea8d-e6742ca9adf4"
      },
      "source": [
        "top_codes = np.argsort(train_y)[-10:]\n",
        "[[code2token[c[0]], code2token[c[1]]] for c in codes[top_codes, :2]]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['norris', 'roundhouse'],\n",
              " ['palpatine', 'skywalker'],\n",
              " ['palpatine', 'sith'],\n",
              " ['roundhouse', 'norris'],\n",
              " ['lankan', 'sri'],\n",
              " ['palpatine', 'anakin'],\n",
              " ['skywalker', 'palpatine'],\n",
              " ['anakin', 'palpatine'],\n",
              " ['blahblah', 'blah'],\n",
              " ['blah', 'blahblah']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XLbwEFXcPfs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5eb4dab-f967-4bd3-c30b-6914ac7e7096"
      },
      "source": [
        "n_user = np.max(train_x[:, :2]) + 1\n",
        "n_item = np.max(train_x[:, :2]) + 1\n",
        "n_user"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v62eEP4lcPfu",
        "colab_type": "text"
      },
      "source": [
        "### Define the MF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnHZNsWwcPfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def l2_regularize(array):\n",
        "    loss = torch.sum(array ** 2.0)\n",
        "    return loss\n",
        "\n",
        "\n",
        "class MF(nn.Module):\n",
        "    itr = 0\n",
        "    \n",
        "    def __init__(self, n_user, n_item, k=18, c_vector=1.0, c_bias=1.0, writer=None):\n",
        "        super(MF, self).__init__()\n",
        "        self.writer = writer\n",
        "        self.k = k\n",
        "        self.n_user = n_user\n",
        "        self.n_item = n_item\n",
        "        self.c_bias = c_bias\n",
        "        self.c_vector = c_vector\n",
        "        self.user = nn.Embedding(n_user, k)\n",
        "        self.item = nn.Embedding(n_item, k)\n",
        "        self.user.weight.data.normal_(0, 1.0 / n_user)\n",
        "        self.item.weight.data.normal_(0, 1.0 / n_item)\n",
        "        \n",
        "        # We've added new terms here:\n",
        "        self.bias_user = nn.Embedding(n_user, 1)\n",
        "        self.bias_item = nn.Embedding(n_item, 1)\n",
        "        self.bias = nn.Parameter(torch.ones(1))\n",
        "\n",
        "    \n",
        "    def __call__(self, train_x):\n",
        "        user_id = train_x[:, 0]\n",
        "        item_id = train_x[:, 1]\n",
        "        vector_user = self.user(user_id)\n",
        "        vector_item = self.item(item_id)\n",
        "        bias_user = self.bias_user(user_id).squeeze()\n",
        "        bias_item = self.bias_item(item_id).squeeze()\n",
        "        biases = (self.bias + bias_user + bias_item)\n",
        "        ui_interaction = torch.sum(vector_user * vector_item, dim=1)\n",
        "        prediction = ui_interaction + biases\n",
        "        return prediction\n",
        "    \n",
        "    def loss(self, prediction, target):\n",
        "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
        "        prior_bias_user =  l2_regularize(self.bias_user.weight) * self.c_bias\n",
        "        prior_bias_item = l2_regularize(self.bias_item.weight) * self.c_bias\n",
        "        prior_user =  l2_regularize(self.user.weight) * self.c_vector\n",
        "        prior_item = l2_regularize(self.item.weight) * self.c_vector\n",
        "        total = loss_mse #+ prior_user + prior_item\n",
        "        for name, var in locals().items():\n",
        "            if type(var) is torch.Tensor and var.nelement() == 1 and self.writer is not None:\n",
        "                self.writer.add_scalar(name, var, self.itr)\n",
        "        return total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqsz4OoWcPfx",
        "colab_type": "text"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfDbHJsGcPfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Loss\n",
        "from tensorboardX import SummaryWriter\n",
        "from ignite.metrics import MeanSquaredError\n",
        "\n",
        "from loader import Loader\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4m7hS17cPf0",
        "colab_type": "text"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHm_dI-VcPf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "796a9bec-4393-495c-d504-19a531c1fa10"
      },
      "source": [
        "lr = 1e-3\n",
        "k = 128\n",
        "c_bias = 1e-9\n",
        "c_vector = 1e-9\n",
        "log_dir = 'runs/simple_mf_05_word2vec_' + str(datetime.now()).replace(' ', '_')\n",
        "print(log_dir)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "runs/simple_mf_05_word2vec_2019-11-18_17:14:14.092277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRZocN7McPf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0447ac42-fa4f-45ec-8735-a1371ad359ed"
      },
      "source": [
        "writer = SummaryWriter(log_dir=log_dir)\n",
        "model = MF(n_user, n_item,  k=k, c_bias=c_bias, \n",
        "           c_vector=c_vector, writer=writer)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "trainer = create_supervised_trainer(model, optimizer, model.loss)\n",
        "metrics = {'accuracy': MeanSquaredError()}\n",
        "train_loader = Loader(train_x, train_y, batchsize=1024)\n",
        "\n",
        "\n",
        "def log_training_loss(engine, log_interval=400):\n",
        "    epoch = engine.state.epoch\n",
        "    itr = engine.state.iteration\n",
        "    fmt = \"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
        "    msg = fmt.format(epoch, itr, len(train_loader), engine.state.output)\n",
        "    model.itr = itr\n",
        "    if itr % log_interval == 0:\n",
        "        print(msg)\n",
        "\n",
        "trainer.add_event_handler(event_name=Events.ITERATION_COMPLETED, handler=log_training_loss)\n",
        "\n",
        "model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MF(\n",
              "  (user): Embedding(14003, 128)\n",
              "  (item): Embedding(14003, 128)\n",
              "  (bias_user): Embedding(14003, 1)\n",
              "  (bias_item): Embedding(14003, 1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKf8qTFLcPf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_state_dict(torch.load(\"model_05_word2vec\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTV482dAcPf8",
        "colab_type": "text"
      },
      "source": [
        "#### Run model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFNj1XY9cPf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "b169a07a-267d-45be-c795-a2c681a420d8"
      },
      "source": [
        "trainer.run(train_loader, max_epochs=5)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch[1] Iteration[400/60208] Loss: 0.40\n",
            "Epoch[1] Iteration[800/60208] Loss: 0.32\n",
            "Epoch[1] Iteration[1200/60208] Loss: 0.33\n",
            "Epoch[1] Iteration[1600/60208] Loss: 0.33\n",
            "Epoch[1] Iteration[2000/60208] Loss: 0.32\n",
            "Epoch[1] Iteration[2400/60208] Loss: 0.36\n",
            "Epoch[1] Iteration[2800/60208] Loss: 0.33\n",
            "Epoch[1] Iteration[3200/60208] Loss: 0.37\n",
            "Epoch[1] Iteration[3600/60208] Loss: 0.36\n",
            "Epoch[1] Iteration[4000/60208] Loss: 0.39\n",
            "Epoch[1] Iteration[4400/60208] Loss: 0.35\n",
            "Epoch[1] Iteration[4800/60208] Loss: 0.34\n",
            "Epoch[1] Iteration[5200/60208] Loss: 0.34\n",
            "Epoch[1] Iteration[5600/60208] Loss: 0.38\n",
            "Epoch[1] Iteration[6000/60208] Loss: 0.36\n",
            "Epoch[1] Iteration[6400/60208] Loss: 0.35\n",
            "Epoch[1] Iteration[6800/60208] Loss: 0.34\n",
            "Epoch[1] Iteration[7200/60208] Loss: 0.36\n",
            "Epoch[1] Iteration[7600/60208] Loss: 0.33\n",
            "Epoch[1] Iteration[8000/60208] Loss: 0.35\n",
            "Epoch[1] Iteration[8400/60208] Loss: 0.35\n",
            "Epoch[1] Iteration[8800/60208] Loss: 0.35\n",
            "Epoch[1] Iteration[9200/60208] Loss: 0.33\n",
            "Epoch[1] Iteration[9600/60208] Loss: 0.36\n",
            "Epoch[1] Iteration[10000/60208] Loss: 0.33\n",
            "Epoch[1] Iteration[10400/60208] Loss: 0.36\n",
            "Epoch[1] Iteration[10800/60208] Loss: 0.39\n",
            "Epoch[1] Iteration[11200/60208] Loss: 0.36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-75d8cbb5c6f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Engine run is terminating due to exception: %s.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch[%s] Complete. Time taken: %02d:%02d:%02d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current run is terminating due to exception: %s.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate_single_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ignite/engine/__init__.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcV_u-IocPf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), \"model_05_word2vec\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkPZbGnpcPgB",
        "colab_type": "text"
      },
      "source": [
        "#### Save the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgpvkDgacPgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_token = ['|' + code2token[c] for c in range(n_user)]\n",
        "writer.add_embedding(model.user.weight)\n",
        "# writer.add_embedding(model.item.weight, metadata=label_token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnh7zhm3cPgE",
        "colab_type": "text"
      },
      "source": [
        "### Introspect the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "686lzGoHcPgE",
        "colab_type": "text"
      },
      "source": [
        "Evaluate what urban dictionary thinks are similar words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCEO5aS2cPgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors_raw = model.user.weight.data.numpy()\n",
        "vectors = vectors_raw / np.sqrt((vectors_raw**2.0).sum(axis=1)[:, None])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNeV4tetcPgH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d58575c8-346c-4bd0-ded8-5f22c8eb2bf2"
      },
      "source": [
        "(vectors[0]**2.0).sum()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT2EF9yPcPgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_closest(token, n=10):\n",
        "    code = token2code[token]\n",
        "    vector = vectors[code]\n",
        "    similarity = np.sum(vector[None, :] * vectors, axis=1)\n",
        "    closest = np.argsort(similarity)[::-1]\n",
        "    for code in closest[1:n]:\n",
        "        print(code2token[code], similarity[code])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv2sVQ5pwgkk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ4AqfJ7cPgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find_closest('buddy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBswZd0hcPgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find_closest('netflix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0nmbYzDcPgT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b4840ef4-6c03-4670-d015-45ab8da77531"
      },
      "source": [
        "find_closest('lol')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wtf 0.6969316\n",
            "omg 0.63160586\n",
            "chat 0.61380476\n",
            "sentence 0.59619784\n",
            "lmao 0.59193116\n",
            "exclamation 0.58523846\n",
            "fucking 0.57547843\n",
            "okay 0.5560159\n",
            "sarcastic 0.5513972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JghH6MHkcPgY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e9c04766-fe32-4bcb-c754-31bc0cff28de"
      },
      "source": [
        "find_closest('hipster')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hipsters 0.88544536\n",
            "trend 0.71011996\n",
            "trendy 0.68734103\n",
            "vintage 0.6783373\n",
            "irony 0.65521455\n",
            "lifestyle 0.6384958\n",
            "poser 0.6250876\n",
            "pseudo 0.62091\n",
            "apparel 0.6172849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBWxnUwkcPgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "709a7667-d224-4671-e46d-032aefd7f189"
      },
      "source": [
        "find_closest('groovy')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stoke 0.7567512\n",
            "fking 0.7518922\n",
            "superlative 0.7504008\n",
            "chica 0.74067503\n",
            "bish 0.73753893\n",
            "interweb 0.7356944\n",
            "positively 0.73289555\n",
            "keepin 0.7324183\n",
            "stoopid 0.73232865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpW2y5mVcPgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "de760222-da97-457a-a81f-08638db52251"
      },
      "source": [
        "find_closest('bromance')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "romantically 0.75557\n",
            "breakup 0.72278714\n",
            "boyband 0.7100685\n",
            "seriousness 0.70013523\n",
            "transexual 0.68761116\n",
            "occurance 0.67989516\n",
            "dougie 0.67773867\n",
            "adulthood 0.67710125\n",
            "bicep 0.67480135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7WD-hNXcPgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "610add24-d5b0-4466-d491-e331bf621a7b"
      },
      "source": [
        "find_closest('barbie')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beyonce 0.66295004\n",
            "perfume 0.6580868\n",
            "wears 0.65606767\n",
            "conceited 0.6560676\n",
            "uggs 0.64748824\n",
            "scrawny 0.64467466\n",
            "playboy 0.63841116\n",
            "flaunt 0.63677084\n",
            "lindsey 0.6353951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjfcNK75cPgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c8e7d646-4731-4bf1-a093-25a408ce4d6c"
      },
      "source": [
        "find_closest('relationship')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "romantic 0.6596911\n",
            "feeling 0.6573658\n",
            "emotional 0.64004\n",
            "boyfriend 0.63267493\n",
            "sexual 0.6303102\n",
            "emotionally 0.62390065\n",
            "date 0.62243676\n",
            "gender 0.61617076\n",
            "marriage 0.61408424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtFeW2BfcPgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "4285d4a0-a6de-4534-bfad-ad044acb8734"
      },
      "source": [
        "find_closest('pope')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "orthodox 0.7538525\n",
            "protestant 0.7532119\n",
            "salvation 0.747226\n",
            "christ 0.72912985\n",
            "believer 0.7162583\n",
            "prophecy 0.69885087\n",
            "mormon 0.6944531\n",
            "preach 0.6928031\n",
            "jehovah 0.6872361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmnKuOntcPgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find_closest('trump')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGIlOYfNcPgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "6fe158c8-65d7-46c9-c22d-2bd6c81da5c7"
      },
      "source": [
        "find_closest('selfie')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hashtag 0.7857493\n",
            "instagram 0.7831992\n",
            "whoring 0.77077365\n",
            "dom 0.7467062\n",
            "googling 0.7387742\n",
            "twit 0.7380605\n",
            "unappealing 0.7342712\n",
            "backstabber 0.7333068\n",
            "downer 0.7327473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGJlv7oBcPgs",
        "colab_type": "text"
      },
      "source": [
        "### Subtract and add word vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E67tXq2-cPgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_subtract(center, minus, plus, n=10):\n",
        "    vector = (vectors[token2code[center]]\n",
        "             - vectors[token2code[minus]]\n",
        "             + vectors[token2code[plus]])\n",
        "    similarity = np.sum(vector[None, :] * vectors, axis=1)\n",
        "    closest = np.argsort(similarity)[::-1]\n",
        "    for code in closest[2:n]:\n",
        "      tok = code2token[code]\n",
        "      if tok != center and tok != minus and tok != plus:\n",
        "        print(code2token[code])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9diHsGJ_cPgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3b21a917-b763-4228-b37c-c793514c4438"
      },
      "source": [
        "add_subtract('burrito', 'mexican', 'italian')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pasta\n",
            "italian\n",
            "cheeseburger\n",
            "hamburger\n",
            "bun\n",
            "bagel\n",
            "pastry\n",
            "ketchup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiIip9pAcPgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add_subtract('drunk', 'beer', 'weed')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKJQCvUw5Xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}