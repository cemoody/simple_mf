{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "05 Simple MF Biases is actually word2vec.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIxp6FWocPfa",
        "colab_type": "text"
      },
      "source": [
        "### Load preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1TiVdQwgWOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "7ec041cb-7c28-47e9-c3de-bcb0db5899b3"
      },
      "source": [
        "!pip install pytorch-ignite tensorboardX\n",
        "!wget https://raw.githubusercontent.com/cemoody/simple_mf/master/notebooks/loader.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (1.9)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.3.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (41.6.0)\n",
            "--2019-11-18 17:14:01--  https://raw.githubusercontent.com/cemoody/simple_mf/master/notebooks/loader.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1014 [text/plain]\n",
            "Saving to: ‘loader.py’\n",
            "\n",
            "loader.py           100%[===================>]    1014  --.-KB/s    in 0s      \n",
            "\n",
            "2019-11-18 17:14:02 (210 MB/s) - ‘loader.py’ saved [1014/1014]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQChQX4gcTPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "6ad170e8-48d9-4514-f0d4-174304e7c025"
      },
      "source": [
        "!wget https://www.dropbox.com/s/nd1zxh538o6psal/skipgram_full.npz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-18 16:56:06--  https://www.dropbox.com/s/nd1zxh538o6psal/skipgram_full.npz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/nd1zxh538o6psal/skipgram_full.npz [following]\n",
            "--2019-11-18 16:56:07--  https://www.dropbox.com/s/raw/nd1zxh538o6psal/skipgram_full.npz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com/cd/0/inline/AsmCMf93WirnSmlkzuHxQU9OZaut_5lNSJmuaLVWNkpIv7Jvhj0xvCcbpGI0ToG7EY76LroIZpy9Ro62uhgwD7tWglNGA3WSHZjlL_KzGf-FMQ/file# [following]\n",
            "--2019-11-18 16:56:07--  https://uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com/cd/0/inline/AsmCMf93WirnSmlkzuHxQU9OZaut_5lNSJmuaLVWNkpIv7Jvhj0xvCcbpGI0ToG7EY76LroIZpy9Ro62uhgwD7tWglNGA3WSHZjlL_KzGf-FMQ/file\n",
            "Resolving uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com (uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com (uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/Asl5bUKLiLagUBYFzf8fU7dO8PT2aEAZWbn5q2_Xwc78lQchIDHYLp_epJMsyzh9nyAbZa0BAeu-OHKe4ch35mwbRhPYO4XnhEARmAQ7ycXi2WWQ74-qqZRow4_VU7lyDV2t3egM1q7uPunGJQ2Gv0ApfgCQ3-5thrAaWLGaL7cSBeLCxFU0I-EWd4UXW9wOuifMWj-t_U7SHFerhUumw0c60f4tUi2hXN3knZHuKdgGiZJlHaqT6xZr4pSGfwUG_f_plMna6BabJPWCONoAbpq3LPkl5RulmU2JhavJdxUOMnb37eGefT6mWKJtEcOUTHI4V1By_5mJtsjTe_Z5_Gld/file [following]\n",
            "--2019-11-18 16:56:08--  https://uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com/cd/0/inline2/Asl5bUKLiLagUBYFzf8fU7dO8PT2aEAZWbn5q2_Xwc78lQchIDHYLp_epJMsyzh9nyAbZa0BAeu-OHKe4ch35mwbRhPYO4XnhEARmAQ7ycXi2WWQ74-qqZRow4_VU7lyDV2t3egM1q7uPunGJQ2Gv0ApfgCQ3-5thrAaWLGaL7cSBeLCxFU0I-EWd4UXW9wOuifMWj-t_U7SHFerhUumw0c60f4tUi2hXN3knZHuKdgGiZJlHaqT6xZr4pSGfwUG_f_plMna6BabJPWCONoAbpq3LPkl5RulmU2JhavJdxUOMnb37eGefT6mWKJtEcOUTHI4V1By_5mJtsjTe_Z5_Gld/file\n",
            "Reusing existing connection to uc979bf5be5f3ed518428ba5623d.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 987227756 (941M) [application/octet-stream]\n",
            "Saving to: ‘skipgram_full.npz’\n",
            "\n",
            "skipgram_full.npz   100%[===================>] 941.49M  48.1MB/s    in 7m 5s   \n",
            "\n",
            "2019-11-18 17:03:13 (2.22 MB/s) - ‘skipgram_full.npz’ saved [987227756/987227756]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQETdenXcPfc",
        "colab_type": "text"
      },
      "source": [
        "If you'd like to play around with this notebook, start by downloading the skipgram dataset from here:\n",
        "\n",
        "https://www.dropbox.com/s/nd1zxh538o6psal/skipgram_full.npz\n",
        "\n",
        "WARNING: it's a 1Gb download, so it may take a while!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2ULzzpecPfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "codes = np.load(\"skipgram_full.npz\")['coded']\n",
        "# Remove duplicate skipgrams\n",
        "codes = codes[codes[:, 0] != codes[:, 1]]\n",
        "code2token = np.load(\"skipgram_full.npz\", allow_pickle=True)['c2t'].tolist()\n",
        "token2code = np.load(\"skipgram_full.npz\", allow_pickle=True)['t2c'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dpA_eiMcPfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "666d7d9a-9789-4706-bb61-2430911e15f3"
      },
      "source": [
        "# First column is the first token code\n",
        "# second column is the 2nd token code\n",
        "# third column is the skip gram count\n",
        "# fourth is PMI * 1e6\n",
        "codes"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  13835,    3257,    4605,  592814],\n",
              "       [  12071,    3257,      16,  491071],\n",
              "       [   4136,    3257,       2, -621270],\n",
              "       ...,\n",
              "       [  12293,    1390,       1, 1092727],\n",
              "       [   5103,    1390,       1, 2368132],\n",
              "       [   6789,    1390,       1,  427689]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAXh1bfQcPfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "62277727-6add-4219-f0b7-a160576b74e9"
      },
      "source": [
        "train_x = codes[:, :2].copy().astype(np.int64)\n",
        "train_y = codes[:, 3].astype(np.float32) / 1e6\n",
        "train_y"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.592814,  0.491071, -0.62127 , ...,  1.092727,  2.368132,\n",
              "        0.427689], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOGuDRkzcPfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f815d303-9d70-4a00-8f79-5ae9d8a04834"
      },
      "source": [
        "train_y.max()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.09618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCV2ioOhcPfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3ad02e4b-19ca-49f7-ea8d-e6742ca9adf4"
      },
      "source": [
        "top_codes = np.argsort(train_y)[-10:]\n",
        "[[code2token[c[0]], code2token[c[1]]] for c in codes[top_codes, :2]]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['norris', 'roundhouse'],\n",
              " ['palpatine', 'skywalker'],\n",
              " ['palpatine', 'sith'],\n",
              " ['roundhouse', 'norris'],\n",
              " ['lankan', 'sri'],\n",
              " ['palpatine', 'anakin'],\n",
              " ['skywalker', 'palpatine'],\n",
              " ['anakin', 'palpatine'],\n",
              " ['blahblah', 'blah'],\n",
              " ['blah', 'blahblah']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XLbwEFXcPfs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5eb4dab-f967-4bd3-c30b-6914ac7e7096"
      },
      "source": [
        "n_user = np.max(train_x[:, :2]) + 1\n",
        "n_item = np.max(train_x[:, :2]) + 1\n",
        "n_user"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v62eEP4lcPfu",
        "colab_type": "text"
      },
      "source": [
        "### Define the MF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnHZNsWwcPfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def l2_regularize(array):\n",
        "    loss = torch.sum(array ** 2.0)\n",
        "    return loss\n",
        "\n",
        "\n",
        "class MF(nn.Module):\n",
        "    itr = 0\n",
        "    \n",
        "    def __init__(self, n_user, n_item, k=18, c_vector=1.0, c_bias=1.0, writer=None):\n",
        "        super(MF, self).__init__()\n",
        "        self.writer = writer\n",
        "        self.k = k\n",
        "        self.n_user = n_user\n",
        "        self.n_item = n_item\n",
        "        self.c_bias = c_bias\n",
        "        self.c_vector = c_vector\n",
        "        self.user = nn.Embedding(n_user, k)\n",
        "        self.item = nn.Embedding(n_item, k)\n",
        "        self.user.weight.data.normal_(0, 1.0 / n_user)\n",
        "        self.item.weight.data.normal_(0, 1.0 / n_item)\n",
        "        \n",
        "        # We've added new terms here:\n",
        "        self.bias_user = nn.Embedding(n_user, 1)\n",
        "        self.bias_item = nn.Embedding(n_item, 1)\n",
        "        self.bias = nn.Parameter(torch.ones(1))\n",
        "\n",
        "    \n",
        "    def __call__(self, train_x):\n",
        "        user_id = train_x[:, 0]\n",
        "        item_id = train_x[:, 1]\n",
        "        vector_user = self.user(user_id)\n",
        "        vector_item = self.item(item_id)\n",
        "        bias_user = self.bias_user(user_id).squeeze()\n",
        "        bias_item = self.bias_item(item_id).squeeze()\n",
        "        biases = (self.bias + bias_user + bias_item)\n",
        "        ui_interaction = torch.sum(vector_user * vector_item, dim=1)\n",
        "        prediction = ui_interaction + biases\n",
        "        return prediction\n",
        "    \n",
        "    def loss(self, prediction, target):\n",
        "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
        "        prior_bias_user =  l2_regularize(self.bias_user.weight) * self.c_bias\n",
        "        prior_bias_item = l2_regularize(self.bias_item.weight) * self.c_bias\n",
        "        prior_user =  l2_regularize(self.user.weight) * self.c_vector\n",
        "        prior_item = l2_regularize(self.item.weight) * self.c_vector\n",
        "        total = loss_mse #+ prior_user + prior_item\n",
        "        for name, var in locals().items():\n",
        "            if type(var) is torch.Tensor and var.nelement() == 1 and self.writer is not None:\n",
        "                self.writer.add_scalar(name, var, self.itr)\n",
        "        return total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqsz4OoWcPfx",
        "colab_type": "text"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfDbHJsGcPfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Loss\n",
        "from tensorboardX import SummaryWriter\n",
        "from ignite.metrics import MeanSquaredError\n",
        "\n",
        "from loader import Loader\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4m7hS17cPf0",
        "colab_type": "text"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHm_dI-VcPf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "796a9bec-4393-495c-d504-19a531c1fa10"
      },
      "source": [
        "lr = 1e-3\n",
        "k = 128\n",
        "c_bias = 1e-9\n",
        "c_vector = 1e-9\n",
        "log_dir = 'runs/simple_mf_05_word2vec_' + str(datetime.now()).replace(' ', '_')\n",
        "print(log_dir)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "runs/simple_mf_05_word2vec_2019-11-18_17:14:14.092277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRZocN7McPf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0447ac42-fa4f-45ec-8735-a1371ad359ed"
      },
      "source": [
        "writer = SummaryWriter(log_dir=log_dir)\n",
        "model = MF(n_user, n_item,  k=k, c_bias=c_bias, \n",
        "           c_vector=c_vector, writer=writer)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "trainer = create_supervised_trainer(model, optimizer, model.loss)\n",
        "metrics = {'accuracy': MeanSquaredError()}\n",
        "train_loader = Loader(train_x, train_y, batchsize=1024)\n",
        "\n",
        "\n",
        "def log_training_loss(engine, log_interval=400):\n",
        "    epoch = engine.state.epoch\n",
        "    itr = engine.state.iteration\n",
        "    fmt = \"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
        "    msg = fmt.format(epoch, itr, len(train_loader), engine.state.output)\n",
        "    model.itr = itr\n",
        "    if itr % log_interval == 0:\n",
        "        print(msg)\n",
        "\n",
        "trainer.add_event_handler(event_name=Events.ITERATION_COMPLETED, handler=log_training_loss)\n",
        "\n",
        "model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MF(\n",
              "  (user): Embedding(14003, 128)\n",
              "  (item): Embedding(14003, 128)\n",
              "  (bias_user): Embedding(14003, 1)\n",
              "  (bias_item): Embedding(14003, 1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKf8qTFLcPf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_state_dict(torch.load(\"model_05_word2vec\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTV482dAcPf8",
        "colab_type": "text"
      },
      "source": [
        "#### Run model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFNj1XY9cPf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a07ebe6d-277e-4c6b-e428-1cfb7d431c1c"
      },
      "source": [
        "trainer.run(train_loader, max_epochs=25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch[1] Iteration[400/60208] Loss: 2.97\n",
            "Epoch[1] Iteration[800/60208] Loss: 1.66\n",
            "Epoch[1] Iteration[1200/60208] Loss: 1.00\n",
            "Epoch[1] Iteration[1600/60208] Loss: 0.81\n",
            "Epoch[1] Iteration[2000/60208] Loss: 0.64\n",
            "Epoch[1] Iteration[2400/60208] Loss: 0.63\n",
            "Epoch[1] Iteration[2800/60208] Loss: 0.58\n",
            "Epoch[1] Iteration[3200/60208] Loss: 0.54\n",
            "Epoch[1] Iteration[3600/60208] Loss: 0.56\n",
            "Epoch[1] Iteration[4000/60208] Loss: 0.49\n",
            "Epoch[1] Iteration[4400/60208] Loss: 0.51\n",
            "Epoch[1] Iteration[4800/60208] Loss: 0.56\n",
            "Epoch[1] Iteration[5200/60208] Loss: 0.55\n",
            "Epoch[1] Iteration[5600/60208] Loss: 0.53\n",
            "Epoch[1] Iteration[6000/60208] Loss: 0.52\n",
            "Epoch[1] Iteration[6400/60208] Loss: 0.47\n",
            "Epoch[1] Iteration[6800/60208] Loss: 0.53\n",
            "Epoch[1] Iteration[7200/60208] Loss: 0.48\n",
            "Epoch[1] Iteration[7600/60208] Loss: 0.53\n",
            "Epoch[1] Iteration[8000/60208] Loss: 0.53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcV_u-IocPf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), \"model_05_word2vec\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkPZbGnpcPgB",
        "colab_type": "text"
      },
      "source": [
        "#### Save the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgpvkDgacPgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_token = ['|' + code2token[c] for c in range(n_user)]\n",
        "writer.add_embedding(model.user.weight)\n",
        "# writer.add_embedding(model.item.weight, metadata=label_token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnh7zhm3cPgE",
        "colab_type": "text"
      },
      "source": [
        "### Introspect the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "686lzGoHcPgE",
        "colab_type": "text"
      },
      "source": [
        "Evaluate what urban dictionary thinks are similar words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCEO5aS2cPgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors_raw = model.user.weight.data.numpy()\n",
        "vectors = vectors_raw / np.sqrt((vectors_raw**2.0).sum(axis=1)[:, None])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNeV4tetcPgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(vectors[0]**2.0).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT2EF9yPcPgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_closest(token, n=10):\n",
        "    code = token2code[token]\n",
        "    vector = vectors[code]\n",
        "    similarity = np.sum(vector[None, :] * vectors, axis=1)\n",
        "    closest = np.argsort(similarity)[::-1]\n",
        "    for code in closest[1:n]:\n",
        "        print(code2token[code], similarity[code])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ4AqfJ7cPgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_closest('dude')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBswZd0hcPgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_closest('netflix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0nmbYzDcPgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_closest('lol')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JghH6MHkcPgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_closest('hipster')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBWxnUwkcPgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_closest('crunk')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpW2y5mVcPgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_closest('bromance')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7WD-hNXcPgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_closest('barbie')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjfcNK75cPgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_closest('relationship')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtFeW2BfcPgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_closest('pope')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmnKuOntcPgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_closest('trump')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGIlOYfNcPgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_closest('selfie')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGJlv7oBcPgs",
        "colab_type": "text"
      },
      "source": [
        "### Subtract and add word vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E67tXq2-cPgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_subtract(center, minus, plus, n=10):\n",
        "    vector = (vectors[token2code[center]]\n",
        "             - vectors[token2code[minus]]\n",
        "             + vectors[token2code[plus]])\n",
        "    similarity = np.sum(vector[None, :] * vectors, axis=1)\n",
        "    closest = np.argsort(similarity)[::-1]\n",
        "    for code in closest[2:n]:\n",
        "        print(code2token[code])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9diHsGJ_cPgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "add_subtract('burrito', 'mexican', 'italian')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiIip9pAcPgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "add_subtract('drunk', 'beer', 'weed')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzpLosgAcPgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}