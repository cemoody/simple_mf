{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iA_qC5BAv6w"
   },
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script that downloads and processes the MovieLens data.\n",
    "Uncomment it to run the download & processing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python ../src/download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "POjwTTneAv6y",
    "outputId": "b3acebb0-47b2-405c-eb40-5474b7aab5c2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fh = np.load('data/dataset.npz', allow_pickle=True)\n",
    "\n",
    "# We have a bunch of feature columns and last column is the y-target\n",
    "# Note pytorch is finicky about need int64 types\n",
    "train_x = fh['train_x'].astype(np.int64)\n",
    "train_y = fh['train_y']\n",
    "train_d = fh['train_dict']\n",
    "\n",
    "# We've already split into train & test\n",
    "test_x = fh['test_x'].astype(np.int64)\n",
    "test_y = fh['test_y']\n",
    "test_d = fh['test_dict']\n",
    "\n",
    "\n",
    "n_user = int(fh['n_user'])\n",
    "n_item = int(fh['n_item'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'Drama': 1.0}, {'Drama': 1.0}, {'Drama': 1.0}, ...,\n",
       "       {'Drama': 1.0}, {'Comedy': 1.0, 'Drama': 1.0, 'Western': 1.0},\n",
       "       {'Documentary': 1.0}], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from abstract_model import AbstractModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Hashed Feature  Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "\n",
    "\n",
    "class HashEmbed(nn.Module):\n",
    "    def __init__(self, n_dim, hash_size=1024):\n",
    "        \"\"\"\n",
    "        A custom module for generating an embedding from\n",
    "        a string feature fields that are hashed and embedded on the fly.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embedding_feats = nn.EmbeddingBag(hash_size, n_dim, mode='sum')\n",
    "        self.hasher = FeatureHasher(hash_size, alternate_sign=False)\n",
    "        self.hash_size = hash_size\n",
    "        torch.nn.init.xavier_uniform_(self.embedding_feats.weight)\n",
    "\n",
    "    def _move(self, arr, device=None):\n",
    "        \"\"\" Transfer the input numpy array to the correct device\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            device = self.embedding_feats.weight.data.device\n",
    "        if 'int' in str(arr.dtype):\n",
    "            arr = arr.astype(np.int64)\n",
    "        if 'float' in str(arr.dtype):\n",
    "            arr = arr.astype(np.float32)\n",
    "        tarr = torch.from_numpy(arr).to(device)\n",
    "        return tarr\n",
    "\n",
    "    def forward(self, features):\n",
    "        flat = np.ravel(features)\n",
    "        items_csr = self.hasher.transform(flat)\n",
    "        n_rows = len(features)\n",
    "        assert items_csr.shape[0] == flat.shape[0]\n",
    "        items_off = self._move(items_csr.indptr[:-1])\n",
    "        items_idx = self._move(items_csr.indices)\n",
    "        items_dat = self._move(items_csr.data)\n",
    "        summed = self.embedding_feats(items_idx, offsets=items_off,\n",
    "                                      per_sample_weights=items_dat)\n",
    "        n_dim = summed.shape[-1]\n",
    "        n_cols = int(np.prod(summed.shape) / n_rows / n_dim)\n",
    "        shape = [n_rows, n_cols, n_dim]\n",
    "        shaped = summed.reshape(shape)\n",
    "        return shaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0343,  0.0373, -0.0761,  0.0539]],\n",
       "\n",
       "        [[ 0.0357, -0.0415, -0.0016,  0.0617]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HashEmbed(4)([{\"dog\": 1.0},  {\"cat\": 1.0}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "def l2_regularize(array):\n",
    "    loss = torch.sum(array ** 2.0)\n",
    "    return loss\n",
    "\n",
    "\n",
    "class MF(AbstractModel):\n",
    "    def __init__(self, n_user, n_item, train_x, train_y, test_x, test_y, \n",
    "                 train_d, test_d,\n",
    "                 k=18, c_vector=1.0, c_bias=1.0, c_feat=1.0, batch_size=128):\n",
    "        super().__init__()\n",
    "        self.save_data(train_x, train_y, test_x, test_y, train_d, test_d)\n",
    "        # These are simple hyperparameters\n",
    "        self.k = k\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.c_vector = c_vector\n",
    "        self.c_bias = c_bias\n",
    "        self.c_feat = c_feat\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # These are learned and fit by PyTorch\n",
    "        self.bias_user = nn.Embedding(n_user, 1)\n",
    "        self.bias_item = nn.Embedding(n_item, 1)\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "        self.user = nn.Embedding(n_user, k)\n",
    "        self.item = nn.Embedding(n_item, k)\n",
    "        self.itemf = HashEmbed(k, hash_size=1024)\n",
    "        self.bias_itemf = HashEmbed(1, hash_size=1024)\n",
    "    \n",
    "    def forward(self, args):\n",
    "        inputs, feat_dict = args\n",
    "        # This is the most import function in this script\n",
    "        # These are the user indices, and correspond to \"u\" variable\n",
    "        user_id = inputs[:, 0]\n",
    "        # Item indices, correspond to the \"i\" variable\n",
    "        item_id = inputs[:, 1]\n",
    "        # vector user = p_u\n",
    "        vector_user = self.user(user_id)\n",
    "        # vector item = q_i\n",
    "        vector_base = self.item(item_id)\n",
    "        \n",
    "        # Newly added: \n",
    "        vector_feat = self.itemf(feat_dict)[:, 0, :]\n",
    "        vector_item = vector_base + vector_feat\n",
    "        bias_feat = self.bias_itemf(feat_dict).squeeze()\n",
    "        \n",
    "        # this is a dot product & a user-item interaction: p_u * q_i\n",
    "        ui_interaction = torch.sum(vector_user * vector_item, dim=1)\n",
    "        \n",
    "        # Pull out biases\n",
    "        bias_user = self.bias_user(user_id).squeeze()\n",
    "        bias_item = self.bias_item(item_id).squeeze()\n",
    "        biases = (self.bias + bias_user + bias_item + bias_feat)\n",
    "\n",
    "        # Add bias prediction to the interaction prediction\n",
    "        prediction = ui_interaction + biases\n",
    "        return prediction\n",
    "    \n",
    "    def likelihood(self, prediction, target):\n",
    "        # MSE error between target = R_ui and prediction = p_u * q_i\n",
    "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
    "        return loss_mse\n",
    "    \n",
    "    def prior(self):\n",
    "        # Add new regularization to the biases\n",
    "        prior_bias_user =  l2_regularize(self.bias_user.weight) * self.c_bias\n",
    "        prior_bias_item = l2_regularize(self.bias_item.weight) * self.c_bias\n",
    "        # Compute L2 reularization over user (P) and item (Q) matrices\n",
    "        prior_user =  l2_regularize(self.user.weight) * self.c_vector\n",
    "        prior_item = l2_regularize(self.item.weight) * self.c_vector\n",
    "        prior_feat = l2_regularize(self.itemf.embedding_feats.weight) * self.c_feat\n",
    "        # Add up the MSE loss + user & item regularization\n",
    "        total = prior_user + prior_item + prior_bias_user + prior_bias_item\n",
    "        return total\n",
    "    \n",
    "\n",
    "\n",
    "model = MF(n_user, n_item, train_x, train_y, test_x, test_y, train_d, test_d)\n",
    "\n",
    "# add a logger\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"mf08_model\")\n",
    "\n",
    "# We could have turned on multiple GPUs here, for example\n",
    "# trainer = pl.Trainer(gpus=8, precision=16)    \n",
    "trainer = pl.Trainer(max_epochs=5,\n",
    "                     reload_dataloaders_every_epoch=True,\n",
    "                     logger=logger)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JR7UIF0vAv69"
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zebJlH2LAv7D"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6314e40933a244288fb90b83a1472c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'test_loss': tensor(27.9933)}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 27.99333381652832}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8AgnqWgCAv7H"
   },
   "source": [
    "#### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "oLvb4afZAv7F",
    "outputId": "c26239cd-63f2-4337-9a84-79aafbce46ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | bias_user  | Embedding | 6 K   \n",
      "1 | bias_item  | Embedding | 3 K   \n",
      "2 | user       | Embedding | 108 K \n",
      "3 | item       | Embedding | 71 K  \n",
      "4 | itemf      | HashEmbed | 18 K  \n",
      "5 | bias_itemf | HashEmbed | 1 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bba2c19237e4c1abf4c54e9c869eab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d37668023804c7c964d5a63ead2f5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'test_loss': tensor(1.2325)}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.2325392961502075}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y69Pl4msAv7M"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "01 Training a simple MF model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
