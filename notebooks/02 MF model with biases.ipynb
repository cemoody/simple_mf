{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iA_qC5BAv6w"
      },
      "source": [
        "### Load preprocessed data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-32CrW7Xnfm7"
      },
      "source": [
        "Run the script that downloads and processes the MovieLens data.\n",
        "Uncomment it to run the download & processing script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-k1EtzLnfm7"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/cemoody/simple_mf/master/src/download.py\n",
        "!wget https://raw.githubusercontent.com/cemoody/simple_mf/master/notebooks/abstract_model.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "TcauNvBUnjfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "tiuuVOf3nk56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "smMTYoz8nmOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python download.py"
      ],
      "metadata": {
        "id": "rfX-ssJznnaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "POjwTTneAv6y",
        "outputId": "b3acebb0-47b2-405c-eb40-5474b7aab5c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 748 1224   24    0]\n",
            " [5255 1064   27   10]\n",
            " [5277 1189   78   20]\n",
            " ...\n",
            " [4379 1246  338    4]\n",
            " [3526  468  105    2]\n",
            " [5812  348  361    7]]\n",
            " \n",
            "[[5.]\n",
            " [5.]\n",
            " [4.]\n",
            " ...\n",
            " [3.]\n",
            " [3.]\n",
            " [5.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import from_numpy\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import BatchSampler\n",
        "from torch.utils.data import RandomSampler\n",
        "\n",
        "fh = np.load('data/dataset.npz')\n",
        "\n",
        "# We have a bunch of feature columns and last column is the y-target\n",
        "# Note pytorch is finicky about need int64 types\n",
        "train_x = fh['train_x'].astype(np.int64)\n",
        "train_y = fh['train_y']\n",
        "\n",
        "# We've already split into train & test\n",
        "X_test = fh['test_x'].astype(np.int64)\n",
        "Y_test = fh['test_y']\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(train_x, train_y)\n",
        "\n",
        "\n",
        "n_user = int(fh['n_user'])\n",
        "n_item = int(fh['n_item'])\n",
        "\n",
        "# columns are user_id, item_id and other features \n",
        "# we won't use the 3rd and 4th columns\n",
        "print(X_train)\n",
        "print(' ')\n",
        "print(Y_train)\n",
        "\n",
        "\n",
        "\n",
        "def dataloader(*arrs, batch_size=32):\n",
        "    dataset = TensorDataset(*arrs)\n",
        "    bs = BatchSampler(RandomSampler(dataset), \n",
        "                      batch_size=batch_size, drop_last=False)\n",
        "    return DataLoader(dataset, batch_sampler=bs, num_workers=8)\n",
        " \n",
        "train = dataloader(from_numpy(X_train), from_numpy(Y_train))\n",
        "test = dataloader(from_numpy(X_test), from_numpy(Y_test))\n",
        "val = dataloader(from_numpy(X_val), from_numpy(Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alfoHm98nfm-"
      },
      "outputs": [],
      "source": [
        "from abstract_model import AbstractModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzJyg-Rtnfm-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "\n",
        "def l2_regularize(array):\n",
        "    return torch.sum(array ** 2.0)\n",
        "\n",
        "\n",
        "class MF(AbstractModel):\n",
        "    def __init__(self, n_user, n_item, k=18, c_vector=1.0, c_bias=1.0, batch_size=128):\n",
        "        super().__init__()\n",
        "        # These are simple hyperparameters\n",
        "        self.k = k\n",
        "        self.n_user = n_user\n",
        "        self.n_item = n_item\n",
        "        self.c_vector = c_vector\n",
        "        self.c_bias = c_bias\n",
        "        self.batch_size = batch_size\n",
        "        self.save_hyperparameters()\n",
        "        \n",
        "        # These are learned and fit by PyTorch\n",
        "        self.user = nn.Embedding(n_user, k)\n",
        "        self.item = nn.Embedding(n_item, k)\n",
        "        \n",
        "        # We've added new terms here:\n",
        "        self.bias_user = nn.Embedding(n_user, 1)\n",
        "        self.bias_item = nn.Embedding(n_item, 1)\n",
        "        self.bias = nn.Parameter(torch.ones(1))\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        # This is the most import function in this script\n",
        "        # These are the user indices, and correspond to \"u\" variable\n",
        "        user_id = inputs[:, 0]\n",
        "        # Item indices, correspond to the \"i\" variable\n",
        "        item_id = inputs[:, 1]\n",
        "        # vector user = p_u\n",
        "        vector_user = self.user(user_id)\n",
        "        # vector item = q_i\n",
        "        vector_item = self.item(item_id)\n",
        "        # this is a dot product & a user-item interaction: p_u * q_i\n",
        "        ui_interaction = torch.sum(vector_user * vector_item, dim=1)\n",
        "        \n",
        "        # Pull out biases\n",
        "        # bias_user shape (bs, 1)\n",
        "        # bias_user.squeeze() shape (bs,)\n",
        "        bias_user = self.bias_user(user_id).squeeze()\n",
        "        bias_item = self.bias_item(item_id).squeeze()\n",
        "        biases = (self.bias + bias_user + bias_item)\n",
        "\n",
        "        # Add bias prediction to the interaction prediction\n",
        "        prediction = ui_interaction + biases\n",
        "        return prediction\n",
        "    \n",
        "    def loss(self, prediction, target):\n",
        "        # MSE error between target = R_ui and prediction = p_u * q_i\n",
        "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
        "        return loss_mse, {\"mse\": loss_mse}\n",
        "    \n",
        "    def reg(self):\n",
        "        # Add new regularization to the biases\n",
        "        reg_bias_user =  l2_regularize(self.bias_user.weight) * self.c_bias\n",
        "        reg_bias_item = l2_regularize(self.bias_item.weight) * self.c_bias\n",
        "        \n",
        "        # Compute L2 reularization over user (P) and item (Q) matrices\n",
        "        reg_user =  l2_regularize(self.user.weight) * self.c_vector\n",
        "        reg_item = l2_regularize(self.item.weight) * self.c_vector\n",
        "        # Add up the MSE loss + user & item regularization\n",
        "        log = {\"reg_user\": reg_user, \"reg_item\": reg_item,\n",
        "               \"reg_bias_user\": reg_bias_user, \"reg_bias_item\": reg_bias_item}\n",
        "        total = reg_user + reg_item + reg_bias_user + reg_bias_item\n",
        "        return total, log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPcNOo_mnfm_"
      },
      "source": [
        "#### Optimize hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y69Pl4msAv7M"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from pytorch_lightning.loggers.wandb import WandbLogger\n",
        "\n",
        "def objective(trial):\n",
        "    # Sample parameters -- without declaring them in advance!\n",
        "    k = trial.suggest_int('n_hid', 1, 20)\n",
        "    # pretty good params are c_bias = 5e-8, c_vector=1e-5, nhid=5\n",
        "    c_vector = trial.suggest_loguniform('c_vector', 1e-8, 1e-1)\n",
        "    c_bias = trial.suggest_loguniform('c_bias', 1e-8, 1e-1)\n",
        "    model = MF(n_user, n_item, k=k, c_bias=c_bias, c_vector=c_vector,\n",
        "              batch_size=1024)\n",
        "    model.save_data(train_x, train_y, test_x, test_y)\n",
        "\n",
        "    # add a logger\n",
        "    logger = WandbLogger(name=\"02_mf\", project=\"simple_mf\")\n",
        "\n",
        "    trainer = pl.Trainer(max_epochs=100, logger=logger,\n",
        "                         early_stop_callback=True,\n",
        "                         gpus=1,\n",
        "                         progress_bar_refresh_rate=1) \n",
        "    trainer.fit(model)\n",
        "    results = trainer.test(model)\n",
        "    return results['avg_test_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RntNCLConfnB",
        "outputId": "05b7cb32-a6c3-43cf-d939-6ddcb227682e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 23:58:34,221] Using an existing study with name 'no-name-1f329d04-352a-4e7f-afb3-546b8be0cfab' instead of creating a new one.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>datetime_start</th>\n",
              "      <th>datetime_complete</th>\n",
              "      <th>duration</th>\n",
              "      <th>params_c_bias</th>\n",
              "      <th>params_c_vector</th>\n",
              "      <th>params_n_hid</th>\n",
              "      <th>system_attrs_fail_reason</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.878160</td>\n",
              "      <td>2020-08-02 05:11:40.629335</td>\n",
              "      <td>2020-08-02 05:37:27.379551</td>\n",
              "      <td>00:25:46.750216</td>\n",
              "      <td>1.221189e-05</td>\n",
              "      <td>9.239021e-08</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.736967</td>\n",
              "      <td>2020-08-02 05:37:27.383097</td>\n",
              "      <td>2020-08-02 06:01:32.865823</td>\n",
              "      <td>00:24:05.482726</td>\n",
              "      <td>5.124483e-08</td>\n",
              "      <td>1.042599e-05</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.783924</td>\n",
              "      <td>2020-08-02 06:01:32.869508</td>\n",
              "      <td>2020-08-02 06:28:04.169764</td>\n",
              "      <td>00:26:31.300256</td>\n",
              "      <td>1.058522e-03</td>\n",
              "      <td>3.165495e-05</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.780473</td>\n",
              "      <td>2020-08-02 06:28:04.174248</td>\n",
              "      <td>2020-08-02 07:01:06.600876</td>\n",
              "      <td>00:33:02.426628</td>\n",
              "      <td>1.526843e-06</td>\n",
              "      <td>4.778658e-07</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.830474</td>\n",
              "      <td>2020-08-02 07:01:06.604357</td>\n",
              "      <td>2020-08-02 07:11:39.575382</td>\n",
              "      <td>00:10:32.971025</td>\n",
              "      <td>4.593979e-08</td>\n",
              "      <td>4.186301e-02</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.784753</td>\n",
              "      <td>2020-08-02 07:11:39.579158</td>\n",
              "      <td>2020-08-02 07:28:37.312584</td>\n",
              "      <td>00:16:57.733426</td>\n",
              "      <td>6.541700e-06</td>\n",
              "      <td>3.501192e-08</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.829048</td>\n",
              "      <td>2020-08-02 07:28:37.317200</td>\n",
              "      <td>2020-08-02 07:40:16.349813</td>\n",
              "      <td>00:11:39.032613</td>\n",
              "      <td>2.767049e-06</td>\n",
              "      <td>5.067678e-03</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.830485</td>\n",
              "      <td>2020-08-02 07:40:16.354294</td>\n",
              "      <td>2020-08-02 07:52:31.056262</td>\n",
              "      <td>00:12:14.701968</td>\n",
              "      <td>3.382782e-07</td>\n",
              "      <td>1.675947e-02</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.953741</td>\n",
              "      <td>2020-08-02 07:52:31.063816</td>\n",
              "      <td>2020-08-02 08:02:43.307739</td>\n",
              "      <td>00:10:12.243923</td>\n",
              "      <td>4.288864e-04</td>\n",
              "      <td>9.926742e-02</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.777146</td>\n",
              "      <td>2020-08-02 08:02:43.311642</td>\n",
              "      <td>2020-08-02 08:27:41.690093</td>\n",
              "      <td>00:24:58.378451</td>\n",
              "      <td>2.949048e-05</td>\n",
              "      <td>1.297505e-07</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>6.598171</td>\n",
              "      <td>2020-08-02 17:19:57.836500</td>\n",
              "      <td>2020-08-02 17:20:16.562713</td>\n",
              "      <td>00:00:18.726213</td>\n",
              "      <td>1.414382e-08</td>\n",
              "      <td>2.555019e-05</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-08-02 17:20:16.600135</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RUNNING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-08-02 17:22:29.453033</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>4.730801e-02</td>\n",
              "      <td>2.915359e-06</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RUNNING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-08-02 17:24:03.599193</td>\n",
              "      <td>2020-08-02 17:24:03.654195</td>\n",
              "      <td>00:00:00.055002</td>\n",
              "      <td>6.272015e-05</td>\n",
              "      <td>4.142618e-06</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Trial 13 failed because of the following error...</td>\n",
              "      <td>FAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-08-02 17:24:16.206847</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>8.663885e-02</td>\n",
              "      <td>8.776650e-06</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RUNNING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.740047</td>\n",
              "      <td>2020-08-02 17:28:14.991580</td>\n",
              "      <td>2020-08-02 17:38:52.966336</td>\n",
              "      <td>00:10:37.974756</td>\n",
              "      <td>3.231526e-02</td>\n",
              "      <td>4.001853e-06</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>0.742316</td>\n",
              "      <td>2020-08-02 17:38:53.012161</td>\n",
              "      <td>2020-08-02 17:56:09.739949</td>\n",
              "      <td>00:17:16.727788</td>\n",
              "      <td>2.867931e-02</td>\n",
              "      <td>6.870542e-06</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>1.229856</td>\n",
              "      <td>2020-08-02 17:56:09.783388</td>\n",
              "      <td>2020-08-02 17:58:17.176547</td>\n",
              "      <td>00:02:07.393159</td>\n",
              "      <td>2.256550e-02</td>\n",
              "      <td>5.052592e-04</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>0.750575</td>\n",
              "      <td>2020-08-02 17:58:17.226506</td>\n",
              "      <td>2020-08-02 18:13:45.504763</td>\n",
              "      <td>00:15:28.278257</td>\n",
              "      <td>3.250728e-04</td>\n",
              "      <td>2.018511e-06</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>1.152578</td>\n",
              "      <td>2020-08-02 18:13:45.544013</td>\n",
              "      <td>2020-08-02 18:15:20.492452</td>\n",
              "      <td>00:01:34.948439</td>\n",
              "      <td>4.013512e-03</td>\n",
              "      <td>3.517525e-04</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>0.829980</td>\n",
              "      <td>2020-08-02 18:15:20.530201</td>\n",
              "      <td>2020-08-02 18:19:30.608758</td>\n",
              "      <td>00:04:10.078557</td>\n",
              "      <td>1.750310e-07</td>\n",
              "      <td>1.505960e-04</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>0.751712</td>\n",
              "      <td>2020-08-02 18:19:30.651939</td>\n",
              "      <td>2020-08-02 18:39:45.199276</td>\n",
              "      <td>00:20:14.547337</td>\n",
              "      <td>1.019992e-08</td>\n",
              "      <td>1.352052e-06</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>0.777255</td>\n",
              "      <td>2020-08-02 18:39:45.253951</td>\n",
              "      <td>2020-08-02 18:57:35.717304</td>\n",
              "      <td>00:17:50.463353</td>\n",
              "      <td>8.736644e-02</td>\n",
              "      <td>2.240586e-05</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>0.744576</td>\n",
              "      <td>2020-08-02 18:57:35.767664</td>\n",
              "      <td>2020-08-02 19:17:49.635617</td>\n",
              "      <td>00:20:13.867953</td>\n",
              "      <td>1.060877e-04</td>\n",
              "      <td>3.069385e-06</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-08-02 19:17:49.675374</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RUNNING</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    number     value             datetime_start          datetime_complete  \\\n",
              "0        0  0.878160 2020-08-02 05:11:40.629335 2020-08-02 05:37:27.379551   \n",
              "1        1  0.736967 2020-08-02 05:37:27.383097 2020-08-02 06:01:32.865823   \n",
              "2        2  0.783924 2020-08-02 06:01:32.869508 2020-08-02 06:28:04.169764   \n",
              "3        3  0.780473 2020-08-02 06:28:04.174248 2020-08-02 07:01:06.600876   \n",
              "4        4  0.830474 2020-08-02 07:01:06.604357 2020-08-02 07:11:39.575382   \n",
              "5        5  0.784753 2020-08-02 07:11:39.579158 2020-08-02 07:28:37.312584   \n",
              "6        6  0.829048 2020-08-02 07:28:37.317200 2020-08-02 07:40:16.349813   \n",
              "7        7  0.830485 2020-08-02 07:40:16.354294 2020-08-02 07:52:31.056262   \n",
              "8        8  0.953741 2020-08-02 07:52:31.063816 2020-08-02 08:02:43.307739   \n",
              "9        9  0.777146 2020-08-02 08:02:43.311642 2020-08-02 08:27:41.690093   \n",
              "10      10  6.598171 2020-08-02 17:19:57.836500 2020-08-02 17:20:16.562713   \n",
              "11      11       NaN 2020-08-02 17:20:16.600135                        NaT   \n",
              "12      12       NaN 2020-08-02 17:22:29.453033                        NaT   \n",
              "13      13       NaN 2020-08-02 17:24:03.599193 2020-08-02 17:24:03.654195   \n",
              "14      14       NaN 2020-08-02 17:24:16.206847                        NaT   \n",
              "15      15  0.740047 2020-08-02 17:28:14.991580 2020-08-02 17:38:52.966336   \n",
              "16      16  0.742316 2020-08-02 17:38:53.012161 2020-08-02 17:56:09.739949   \n",
              "17      17  1.229856 2020-08-02 17:56:09.783388 2020-08-02 17:58:17.176547   \n",
              "18      18  0.750575 2020-08-02 17:58:17.226506 2020-08-02 18:13:45.504763   \n",
              "19      19  1.152578 2020-08-02 18:13:45.544013 2020-08-02 18:15:20.492452   \n",
              "20      20  0.829980 2020-08-02 18:15:20.530201 2020-08-02 18:19:30.608758   \n",
              "21      21  0.751712 2020-08-02 18:19:30.651939 2020-08-02 18:39:45.199276   \n",
              "22      22  0.777255 2020-08-02 18:39:45.253951 2020-08-02 18:57:35.717304   \n",
              "23      23  0.744576 2020-08-02 18:57:35.767664 2020-08-02 19:17:49.635617   \n",
              "24      24       NaN 2020-08-02 19:17:49.675374                        NaT   \n",
              "\n",
              "          duration  params_c_bias  params_c_vector  params_n_hid  \\\n",
              "0  00:25:46.750216   1.221189e-05     9.239021e-08          20.0   \n",
              "1  00:24:05.482726   5.124483e-08     1.042599e-05           5.0   \n",
              "2  00:26:31.300256   1.058522e-03     3.165495e-05          19.0   \n",
              "3  00:33:02.426628   1.526843e-06     4.778658e-07          12.0   \n",
              "4  00:10:32.971025   4.593979e-08     4.186301e-02           2.0   \n",
              "5  00:16:57.733426   6.541700e-06     3.501192e-08           1.0   \n",
              "6  00:11:39.032613   2.767049e-06     5.067678e-03           3.0   \n",
              "7  00:12:14.701968   3.382782e-07     1.675947e-02          10.0   \n",
              "8  00:10:12.243923   4.288864e-04     9.926742e-02          16.0   \n",
              "9  00:24:58.378451   2.949048e-05     1.297505e-07           2.0   \n",
              "10 00:00:18.726213   1.414382e-08     2.555019e-05           7.0   \n",
              "11             NaT            NaN              NaN           NaN   \n",
              "12             NaT   4.730801e-02     2.915359e-06           6.0   \n",
              "13 00:00:00.055002   6.272015e-05     4.142618e-06           6.0   \n",
              "14             NaT   8.663885e-02     8.776650e-06           6.0   \n",
              "15 00:10:37.974756   3.231526e-02     4.001853e-06           6.0   \n",
              "16 00:17:16.727788   2.867931e-02     6.870542e-06           6.0   \n",
              "17 00:02:07.393159   2.256550e-02     5.052592e-04           6.0   \n",
              "18 00:15:28.278257   3.250728e-04     2.018511e-06           9.0   \n",
              "19 00:01:34.948439   4.013512e-03     3.517525e-04          13.0   \n",
              "20 00:04:10.078557   1.750310e-07     1.505960e-04           4.0   \n",
              "21 00:20:14.547337   1.019992e-08     1.352052e-06           8.0   \n",
              "22 00:17:50.463353   8.736644e-02     2.240586e-05           5.0   \n",
              "23 00:20:13.867953   1.060877e-04     3.069385e-06          12.0   \n",
              "24             NaT            NaN              NaN           NaN   \n",
              "\n",
              "                             system_attrs_fail_reason     state  \n",
              "0                                                 NaN  COMPLETE  \n",
              "1                                                 NaN  COMPLETE  \n",
              "2                                                 NaN  COMPLETE  \n",
              "3                                                 NaN  COMPLETE  \n",
              "4                                                 NaN  COMPLETE  \n",
              "5                                                 NaN  COMPLETE  \n",
              "6                                                 NaN  COMPLETE  \n",
              "7                                                 NaN  COMPLETE  \n",
              "8                                                 NaN  COMPLETE  \n",
              "9                                                 NaN  COMPLETE  \n",
              "10                                                NaN  COMPLETE  \n",
              "11                                                NaN   RUNNING  \n",
              "12                                                NaN   RUNNING  \n",
              "13  Trial 13 failed because of the following error...      FAIL  \n",
              "14                                                NaN   RUNNING  \n",
              "15                                                NaN  COMPLETE  \n",
              "16                                                NaN  COMPLETE  \n",
              "17                                                NaN  COMPLETE  \n",
              "18                                                NaN  COMPLETE  \n",
              "19                                                NaN  COMPLETE  \n",
              "20                                                NaN  COMPLETE  \n",
              "21                                                NaN  COMPLETE  \n",
              "22                                                NaN  COMPLETE  \n",
              "23                                                NaN  COMPLETE  \n",
              "24                                                NaN   RUNNING  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study = optuna.create_study(storage='sqlite:///02.db', \n",
        "                            study_name='no-name-1f329d04-352a-4e7f-afb3-546b8be0cfab',\n",
        "                            load_if_exists=True)\n",
        "study.trials_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fKU3pAnnfnB",
        "outputId": "7329a7c3-4557-4999-ebb3-e3ddd626b61f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'study' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-eb1c21439167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_rmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'study' is not defined"
          ]
        }
      ],
      "source": [
        "best_mse = study.best_trial.value\n",
        "best_rmse = np.sqrt(best_mse)\n",
        "best_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H506tSxjnfnC",
        "outputId": "148b6eac-da9b-44e1-9b85-1f0bc3e11d26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'c_bias': 5.124483316506529e-08,\n",
              " 'c_vector': 1.042598682967818e-05,\n",
              " 'n_hid': 5}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hnXJLnZnfnC"
      },
      "outputs": [],
      "source": [
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2x944Y9nfnD"
      },
      "source": [
        "#### Train a model with the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT9EQpaSnfnD",
        "outputId": "d28928c3-178d-478d-df62-2099821a3d7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning:\n",
            "\n",
            "GPU available but not used. Set the --gpus flag when calling the script.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pytorch_lightning.loggers.wandb import WandbLogger\n",
        "\n",
        "k = 5\n",
        "c_vector = 1e-5\n",
        "c_bias = 5e-8\n",
        "model = MF(n_user, n_item, k=k, c_bias=c_bias, c_vector=c_vector,\n",
        "          batch_size=1024)\n",
        "\n",
        "# add a logger\n",
        "logger = WandbLogger(name=\"02_mf\", project=\"simple_mf\")\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=100, logger=logger,\n",
        "                     early_stop_callback=True,\n",
        "                     progress_bar_refresh_rate=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvZq60YSnfnD",
        "outputId": "2b588c4a-7326-43c7-868d-ce3c1869278f",
        "colab": {
          "referenced_widgets": [
            "",
            "a0bdfb80e00742e8b71ca1a5000a91ad"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Waiting for W&B process to finish, PID 14639\n",
            "wandb: Program ended successfully.\n",
            "wandb:                                                                                \n",
            "wandb: Find user logs for this run at: wandb/run-20200925_154151-15e4xlr1/logs/debug.log\n",
            "wandb: Find internal logs for this run at: wandb/run-20200925_154151-15e4xlr1/logs/debug-internal.log\n",
            "wandb: Run summary:\n",
            "wandb:     global_step 611899\n",
            "wandb:             mse 1.2072919607162476\n",
            "wandb:        reg_user 0.01724400743842125\n",
            "wandb:        reg_item 0.015419412404298782\n",
            "wandb:   reg_bias_user 0.00030013531795702875\n",
            "wandb:   reg_bias_item 9.267379209632054e-05\n",
            "wandb:      train_loss 1.240348219871521\n",
            "wandb:           epoch 28\n",
            "wandb:           _step 12266\n",
            "wandb:        _runtime 5635\n",
            "wandb:      _timestamp 1601054148\n",
            "wandb:        val_loss 0.7469817399978638\n",
            "wandb: Run history:\n",
            "wandb:     global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "wandb:             mse █▅▄▃▂▁▅▁▂▂▂▁▁▄▃▂▃▃▃▃▂▃▃▂▂▃▁▂▃▃▁▂▃▃▃▂▄▃▂▃\n",
            "wandb:        reg_user █▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "wandb:        reg_item █▄▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂\n",
            "wandb:   reg_bias_user ▄▂▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇██\n",
            "wandb:   reg_bias_item ▇▂▁▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███\n",
            "wandb:      train_loss █▅▄▃▂▁▄▁▂▂▂▁▁▃▃▂▂▃▃▃▂▃▃▂▂▃▁▂▃▃▁▂▃▃▃▁▄▂▂▃\n",
            "wandb:           epoch ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇███\n",
            "wandb:           _step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "wandb:        _runtime ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███\n",
            "wandb:      _timestamp ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███\n",
            "wandb:        val_loss █▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "wandb: \n",
            "wandb: Synced 02_mf: https://wandb.ai/sf-moody/simple_mf/runs/15e4xlr1\n",
            "wandb: Tracking run with wandb version 0.10.2\n",
            "wandb: Run data is saved locally in wandb/run-20200925_184611-1eeimyck\n",
            "wandb: Syncing run 02_mf\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sf-moody/simple_mf\" target=\"_blank\">https://wandb.ai/sf-moody/simple_mf</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sf-moody/simple_mf/runs/1eeimyck\" target=\"_blank\">https://wandb.ai/sf-moody/simple_mf/runs/1eeimyck</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name      | Type      | Params\n",
            "----------------------------------------\n",
            "0 | user      | Embedding | 30 K  \n",
            "1 | item      | Embedding | 19 K  \n",
            "2 | bias_user | Embedding | 6 K   \n",
            "3 | bias_item | Embedding | 3 K   \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0bdfb80e00742e8b71ca1a5000a91ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning:\n",
            "\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "\n",
            "Saving latest checkpoint..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.fit(model, train, val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fb_DtbfnfnE"
      },
      "outputs": [],
      "source": [
        "trainer.save_checkpoint(\"02_best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnDkiXdOnfnE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "collapsed_sections": [],
      "name": "02 MF Model with biases.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}