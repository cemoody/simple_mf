{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda  uninstall tensorboard; pip uninstall -y tensorboard; conda install tensorboard; conda install pytorch-lightning -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python ../src/download_ml20.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "fh = np.load('data/dataset_ml20_wide.npz')\n",
    "# We have a bunch of feature columns and last column is the y-target\n",
    "max_seq_len = 768 + 1\n",
    "train_items = fh['train_items'].astype(np.int64)[:, :max_seq_len]\n",
    "# Note that ratings are modified are on scale (1, 2, ... 10) \n",
    "train_ratng = fh['train_ratng'].astype(np.int64)[:, :max_seq_len]\n",
    "test_items = fh['test_items'].astype(np.int64)[:, :max_seq_len]\n",
    "test_ratng = fh['test_ratng'].astype(np.int64)[:, :max_seq_len]\n",
    "\n",
    "n_user = train_items.shape[0]\n",
    "n_rank = train_items.shape[1]\n",
    "n_item = int(train_items.max() + 1)\n",
    "n_resp = int(train_ratng.max() + 1)\n",
    "\n",
    "train_items, val_items, train_ratng, val_ratng = train_test_split(train_items, train_ratng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import from_numpy\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import BatchSampler\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "def dataloader(*arrs, batch_size=64):\n",
    "    dataset = TensorDataset(*arrs)\n",
    "    arr_size = len(arrs[0])\n",
    "    bs = BatchSampler(SequentialSampler(range(arr_size)),\n",
    "                      batch_size=batch_size, drop_last=False)\n",
    "    return DataLoader(dataset, batch_sampler=bs, shuffle=False)\n",
    " \n",
    "train = dataloader(from_numpy(train_items), from_numpy(train_ratng))\n",
    "val = dataloader(from_numpy(val_items), from_numpy(val_ratng))\n",
    "test = dataloader(from_numpy(test_items), from_numpy(test_ratng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the inputs are now 2D. Each row in `train_items` represents is a 1D stream of items seen by a single user. Different rows will be from different user streams. Note that each stream is padded with zeros so it is a fixed input size. `train_ratng` is a similar structure, but gives the categorical rating output (scaled from [0.0, 0.5, ... 4.5, 5.0] to [0, 1,2, ...10]) that that user gave that item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 150,  296,  380, ...,    0,    0,    0],\n",
       "       [6377, 2470, 4896, ...,    0,    0,    0],\n",
       "       [   3, 1198, 2779, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 592,  296,  380, ...,    0,    0,    0],\n",
       "       [ 158,   22, 2502, ...,    0,    0,    0],\n",
       "       [ 150,  296,  592, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 10,  6, ...,  0,  0,  0],\n",
       "       [ 8,  6,  8, ...,  0,  0,  0],\n",
       "       [ 4, 10,  8, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 6,  8, 10, ...,  0,  0,  0],\n",
       "       [ 6,  6,  8, ...,  0,  0,  0],\n",
       "       [ 6,  8,  6, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_ratng[train_items > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      2,      3, ..., 131158, 131237, 131262])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((93483, 769), (13849, 769))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_items.shape, test_items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q reformer_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import from_numpy\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from reformer_pytorch import Reformer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstract_model import AbstractModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AR(AbstractModel):\n",
    "    def __init__(self, n_item, n_dim, n_resp, n_rank, \n",
    "                 heads=2, depth=2, batch_size=32, weight_decay=1e-6):\n",
    "        super().__init__()\n",
    "        self.n_dim = n_dim\n",
    "        self.n_item = n_item\n",
    "        self.n_resp = n_resp\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # This means that item=0 will always yield the zero vector\n",
    "        self.item = nn.Embedding(n_item, n_dim, padding_idx=0)\n",
    "        self.resp = nn.Embedding(n_resp, n_dim)\n",
    "        self.reformer = Reformer(dim=n_dim, depth=depth, heads=heads, causal=True, max_seq_len=n_rank)\n",
    "        self.user_lin = nn.Linear(n_dim, n_dim * n_resp)\n",
    "        self.item_lin = nn.Linear(n_dim, n_dim * n_resp)\n",
    "        self.batch_size = batch_size\n",
    "        self.weight_decay = weight_decay\n",
    "    \n",
    "    def forward(self, items, ratng):\n",
    "        item_vec = self.item(items)\n",
    "        resp_vec = self.resp(ratng)\n",
    "        intx_vec = item_vec * resp_vec\n",
    "        mask = items != 0\n",
    "        user_vec = self.reformer(intx_vec, input_mask=mask)\n",
    "        return user_vec\n",
    "    \n",
    "    def loss(self, user_vec, items, ratg):\n",
    "        batchsize, window, n_dim = user_vec.shape\n",
    "        item_vec = self.item(items)\n",
    "        # Linearly map one user & item vector to one user &  item vector\n",
    "        # per possible response type\n",
    "        user_raw_resp = self.user_lin(user_vec).reshape((batchsize, window, n_dim, self.n_resp))\n",
    "        item_raw_resp = self.item_lin(item_vec).reshape((batchsize, window, n_dim, self.n_resp))\n",
    "        # remove first user element and call it the  bias, the  rest is the user vector\n",
    "        # same for items\n",
    "        user_bas_resp, user_vec_resp = user_raw_resp[:, :, 0, :], user_raw_resp[:, :, 1:, :]\n",
    "        item_bas_resp, item_vec_resp = item_raw_resp[:, :, 0, :], item_raw_resp[:, :, 1:, :]\n",
    "        # Sum interactions  across n_dim back down to  (batchsize, window, n_resp)\n",
    "        scor = user_bas_resp + item_bas_resp + (user_vec_resp * item_vec_resp).sum(dim=2)\n",
    "        scor_flat = scor.reshape((batchsize * window, self.n_resp))\n",
    "        ratg_flat = ratg.reshape((batchsize * window))\n",
    "        loss = F.cross_entropy(scor_flat, ratg_flat, ignore_index=0, reduction='mean')\n",
    "        return loss, {\"cross_entropy\": loss}\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4, \n",
    "                                weight_decay=self.weight_decay)\n",
    "\n",
    "    def step(self, batch, batch_nb, prefix='train', add_reg=True):\n",
    "        items, ratng = batch\n",
    "        # Pass in leading arrays, missing the last element\n",
    "        # (hence the [:-1])\n",
    "        # for every user that's to  be predicted\n",
    "        user_vec = self.forward(items[:,  :-1], ratng[:, :-1])\n",
    "        # Given previous tokens, predict the next interaction\n",
    "        loss, log = self.loss(user_vec, items[:, 1:],  ratng[:, 1:])\n",
    "        log[f'{prefix}_loss'] = loss\n",
    "        return {f'{prefix}_loss': loss, 'loss':loss, 'log': log}\n",
    "        \n",
    "    def reg(self):\n",
    "        # Regularize via weight decay instead of explicitly\n",
    "        return 0.0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.logging import WandbLogger\n",
    "\n",
    "n_dim = 32\n",
    "model = AR(n_item, n_dim, n_resp, n_rank, \n",
    "           heads=8, depth=6, batch_size=64)\n",
    "model.save_data(train_items, train_ratng, test_items, test_ratng)\n",
    "logger = WandbLogger(name=\"10_mf\", project=\"simple_mf\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100, logger=logger,\n",
    "                     early_stop_callback=True,\n",
    "                     gpus=1, progress_bar_refresh_rate=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.test(model)\n",
    "results['avg_test_loss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
