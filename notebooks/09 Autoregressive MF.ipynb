{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda  uninstall tensorboard; pip uninstall -y tensorboard; conda install tensorboard; conda install pytorch-lightning -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_item 131263\n",
      "n_user 138494\n",
      "n_features 269757\n",
      "n_rows 19950567\n"
     ]
    }
   ],
   "source": [
    "!python ../src/download_ml20.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "fh = np.load('data/dataset_ml20_wide.npz')\n",
    "# We have a bunch of feature columns and last column is the y-target\n",
    "max_seq_len = 768 + 1\n",
    "train_items = fh['train_items'].astype(np.int64)[:, :max_seq_len]\n",
    "# Note that ratings are modified are on scale (1, 2, ... 10) \n",
    "train_ratng = fh['train_ratng'].astype(np.int64)[:, :max_seq_len]\n",
    "test_items = fh['test_items'].astype(np.int64)[:, :max_seq_len]\n",
    "test_ratng = fh['test_ratng'].astype(np.int64)[:, :max_seq_len]\n",
    "\n",
    "n_user = train_items.shape[0]\n",
    "n_rank = train_items.shape[1]\n",
    "n_item = int(train_items.max() + 1)\n",
    "n_resp = int(train_ratng.max() + 1)\n",
    "\n",
    "train_items, val_items, train_ratng, val_ratng = train_test_split(train_items, train_ratng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import from_numpy\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import BatchSampler\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "def dataloader(*arrs, batch_size=64):\n",
    "    dataset = TensorDataset(*arrs)\n",
    "    arr_size = len(arrs[0])\n",
    "    bs = BatchSampler(SequentialSampler(range(arr_size)),\n",
    "                      batch_size=batch_size, drop_last=False)\n",
    "    return DataLoader(dataset, batch_sampler=bs, shuffle=False)\n",
    " \n",
    "train = dataloader(from_numpy(train_items), from_numpy(train_ratng))\n",
    "val = dataloader(from_numpy(val_items), from_numpy(val_ratng))\n",
    "test = dataloader(from_numpy(test_items), from_numpy(test_ratng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the inputs are now 2D. Each row in `train_items` represents is a 1D stream of items seen by a single user. Different rows will be from different user streams. Note that each stream is padded with zeros so it is a fixed input size. `train_ratng` is a similar structure, but gives the categorical rating output (scaled from [0.0, 0.5, ... 4.5, 5.0] to [0, 1,2, ...10]) that that user gave that item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2012,  471, 2268, ...,    0,    0,    0],\n",
       "       [ 110,  719,  260, ...,    0,    0,    0],\n",
       "       [1586,  107, 3555, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [2640, 7153, 3623, ...,    0,    0,    0],\n",
       "       [2150,  892, 1076, ...,    0,    0,    0],\n",
       "       [1835, 1909, 1912, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 10,  4, ...,  0,  0,  0],\n",
       "       [10,  8,  8, ...,  0,  0,  0],\n",
       "       [ 6,  4, 10, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 7,  6,  5, ...,  0,  0,  0],\n",
       "       [ 8,  8, 10, ...,  0,  0,  0],\n",
       "       [ 4,  8,  8, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_ratng[train_items > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      2,      3, ..., 131170, 131237, 131262])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((93483, 769), (13849, 769))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_items.shape, test_items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q reformer_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import from_numpy\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from reformer_pytorch import Reformer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstract_model import AbstractModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AR(AbstractModel):\n",
    "    def __init__(self, n_item, n_dim, n_resp, n_rank, p=0.1,\n",
    "                 heads=2, depth=2, batch_size=32, weight_decay=1e-6):\n",
    "        super().__init__()\n",
    "        self.n_dim = n_dim\n",
    "        self.n_item = n_item\n",
    "        self.n_resp = n_resp\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # This means that item=0 will always yield the zero vector\n",
    "        self.item = nn.Embedding(n_item, n_dim, padding_idx=0)\n",
    "        self.resp = nn.Embedding(n_resp, n_dim)\n",
    "        self.reformer = Reformer(dim=n_dim, depth=depth, heads=heads, causal=True, max_seq_len=n_rank)\n",
    "        self.batch_size = batch_size\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "    \n",
    "    def forward(self, items, ratng):\n",
    "        item_vec = self.item(items)\n",
    "        resp_vec = self.resp(ratng)\n",
    "        intx_vec = self.dropout(item_vec * resp_vec)\n",
    "        mask = items != 0\n",
    "        user_vec = self.reformer(intx_vec, input_mask=mask)\n",
    "        return user_vec\n",
    "    \n",
    "    def loss(self, user_raw, items, ratg):\n",
    "        # user_vec is (batchsize, window, n_dim)\n",
    "        batchsize, window, n_dim = user_raw.shape\n",
    "        item_raw = self.item(items)\n",
    "        user_bas, user_vec = user_raw[:, :, 0], user_raw[:, :, 1:]\n",
    "        item_bas, item_vec = item_raw[:, :, 0], item_raw[:, :, 1:]\n",
    "        pred = user_bas + item_bas + (user_vec * item_vec).sum(dim=2)\n",
    "        # Ignore ratings that are zero -- zero isn't actually possible from the\n",
    "        # user. Instead zero is empty padding that we should ignore.\n",
    "        mask = ratg != 0\n",
    "        loss_sum = F.mse_loss(pred[mask], ratg[mask] * 1.0, reduction='sum')\n",
    "        loss_mean = loss_sum / (mask.sum() * 1.0)\n",
    "        return loss_mean, {\"mse\": loss_mean}\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4, \n",
    "                                weight_decay=self.weight_decay)\n",
    "\n",
    "    def step(self, batch, batch_nb, prefix='train', add_reg=True):\n",
    "        items, ratng = batch\n",
    "        # Pass in leading arrays, missing the last element\n",
    "        # (hence the [:-1]) for every user that's to  be predicted\n",
    "        user_vec = self.forward(items[:,  :-1], ratng[:, :-1])\n",
    "        # Given previous tokens, predict the next interaction\n",
    "        # hence the [1:] \n",
    "        loss, log = self.loss(user_vec, items[:, 1:],  ratng[:, 1:])\n",
    "        log[f'{prefix}_loss'] = loss\n",
    "        return {f'{prefix}_loss': loss, 'loss':loss, 'log': log}\n",
    "        \n",
    "    def reg(self):\n",
    "        # Regularize via weight decay instead of explicitly\n",
    "        return 0.0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "\n",
    "n_dim = 48\n",
    "model = AR(n_item, n_dim, n_resp, n_rank, \n",
    "           heads=8, depth=6)\n",
    "logger = WandbLogger(name=\"09_mf\", project=\"simple_mf\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100, logger=logger,\n",
    "                     early_stop_callback=True,\n",
    "                     gpus=1, progress_bar_refresh_rate=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16707<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201030_155847-3mdlz6ks/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201030_155847-3mdlz6ks/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">09_mf</strong>: <a href=\"https://wandb.ai/sf-moody/simple_mf/runs/3mdlz6ks\" target=\"_blank\">https://wandb.ai/sf-moody/simple_mf/runs/3mdlz6ks</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.8<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">09_mf</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sf-moody/simple_mf\" target=\"_blank\">https://wandb.ai/sf-moody/simple_mf</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sf-moody/simple_mf/runs/3ssqyobk\" target=\"_blank\">https://wandb.ai/sf-moody/simple_mf/runs/3ssqyobk</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201030_160006-3ssqyobk</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type      | Params\n",
      "---------------------------------------\n",
      "0 | item     | Embedding | 6 M   \n",
      "1 | resp     | Embedding | 528   \n",
      "2 | reformer | Reformer  | 154 K \n",
      "3 | dropout  | Dropout   | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47c6e8b4681441e92cc96a719b563ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.test(model)\n",
    "results['avg_test_loss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
