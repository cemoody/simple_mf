{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBftCvavtHGl"
      },
      "outputs": [],
      "source": [
        "### Load preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phJjS6PHtHGp"
      },
      "outputs": [],
      "source": [
        "# conda  uninstall tensorboard; pip uninstall -y tensorboard; conda install tensorboard; conda install pytorch-lightning -c conda-forge"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/cemoody/simple_mf/master/src/download_ml20.py\n",
        "!wget https://raw.githubusercontent.com/cemoody/simple_mf/master/notebooks/abstract_model.py\n",
        "!pip install pytorch_lightning wandb\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB9q1gwztc2E",
        "outputId": "c55ea0ad-739f-49f8-dc68-d84b87674b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-22 19:28:50--  https://raw.githubusercontent.com/cemoody/simple_mf/master/src/download_ml20.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3503 (3.4K) [text/plain]\n",
            "Saving to: ‘download_ml20.py’\n",
            "\n",
            "download_ml20.py    100%[===================>]   3.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-22 19:28:50 (57.8 MB/s) - ‘download_ml20.py’ saved [3503/3503]\n",
            "\n",
            "--2022-04-22 19:28:50--  https://raw.githubusercontent.com/cemoody/simple_mf/master/notebooks/abstract_model.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1696 (1.7K) [text/plain]\n",
            "Saving to: ‘abstract_model.py’\n",
            "\n",
            "abstract_model.py   100%[===================>]   1.66K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-22 19:28:51 (30.2 MB/s) - ‘abstract_model.py’ saved [1696/1696]\n",
            "\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.6.1-py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 28.3 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.12.15-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 58.6 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 67.4 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.1.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Collecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 54.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.10-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 75.4 MB/s \n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 60.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=34218568a518fc05c4f392eb804bb30a32c90596fef61cebfc09e75aa5edc7a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: multidict, frozenlist, yarl, smmap, asynctest, async-timeout, aiosignal, pyDeprecate, gitdb, fsspec, aiohttp, torchmetrics, shortuuid, setproctitle, sentry-sdk, PyYAML, pathtools, GitPython, docker-pycreds, wandb, pytorch-lightning\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed GitPython-3.1.27 PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 docker-pycreds-0.4.0 frozenlist-1.3.0 fsspec-2022.3.0 gitdb-4.0.9 multidict-6.0.2 pathtools-0.1.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.1 sentry-sdk-1.5.10 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 torchmetrics-0.8.0 wandb-0.12.15 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z9YqAh2ct1fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python download_ml20.py"
      ],
      "metadata": {
        "id": "g1AFezynt1ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1sP4ZzLtHGp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbLZdRPLtHGr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "fh = np.load('data/dataset_ml20_wide.npz')\n",
        "# We have a bunch of feature columns and last column is the y-target\n",
        "max_seq_len = 768 + 1\n",
        "train_items = fh['train_items'].astype(np.int64)[:, :max_seq_len]\n",
        "# Note that ratings are modified are on scale (1, 2, ... 10) \n",
        "train_ratng = fh['train_ratng'].astype(np.int64)[:, :max_seq_len]\n",
        "test_items = fh['test_items'].astype(np.int64)[:, :max_seq_len]\n",
        "test_ratng = fh['test_ratng'].astype(np.int64)[:, :max_seq_len]\n",
        "\n",
        "n_user = train_items.shape[0]\n",
        "n_rank = train_items.shape[1]\n",
        "n_item = int(train_items.max() + 1)\n",
        "n_resp = int(train_ratng.max() + 1)\n",
        "\n",
        "train_items, val_items, train_ratng, val_ratng = train_test_split(train_items, train_ratng)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmLJBdJZtHGs"
      },
      "outputs": [],
      "source": [
        "from torch import from_numpy\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import BatchSampler\n",
        "from torch.utils.data import SequentialSampler\n",
        "\n",
        "def dataloader(*arrs, batch_size=64):\n",
        "    dataset = TensorDataset(*arrs)\n",
        "    arr_size = len(arrs[0])\n",
        "    bs = BatchSampler(SequentialSampler(range(arr_size)),\n",
        "                      batch_size=batch_size, drop_last=False)\n",
        "    return DataLoader(dataset, batch_sampler=bs, shuffle=False)\n",
        " \n",
        "train = dataloader(from_numpy(train_items), from_numpy(train_ratng))\n",
        "val = dataloader(from_numpy(val_items), from_numpy(val_ratng))\n",
        "test = dataloader(from_numpy(test_items), from_numpy(test_ratng))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRuj49BotHGt"
      },
      "source": [
        "#### Data Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d67poEZtHGu"
      },
      "source": [
        "Notice that the inputs are now 2D. Each row in `train_items` represents is a 1D stream of items seen by a single user. Different rows will be from different user streams. Note that each stream is padded with zeros so it is a fixed input size. `train_ratng` is a similar structure, but gives the categorical rating output (scaled from [0.0, 0.5, ... 4.5, 5.0] to [0, 1,2, ...10]) that that user gave that item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_W6r0BgtHGv"
      },
      "outputs": [],
      "source": [
        "train_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghWAHAJVtHGw"
      },
      "outputs": [],
      "source": [
        "train_ratng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35557bjotHGx"
      },
      "outputs": [],
      "source": [
        "np.unique(train_ratng[train_items > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zCacF2ytHGx"
      },
      "outputs": [],
      "source": [
        "np.unique(train_items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGFO3vAptHGy"
      },
      "outputs": [],
      "source": [
        "train_items.shape, test_items.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp_PYLDytHGz"
      },
      "outputs": [],
      "source": [
        "!pip install -q reformer_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFQeMnPItHGz"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch import from_numpy\n",
        "import pytorch_lightning as pl\n",
        "from torch.nn import functional as F\n",
        "from reformer_pytorch import Reformer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5az4EJ-tHGz"
      },
      "outputs": [],
      "source": [
        "from abstract_model import AbstractModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qotX52sWtHG0"
      },
      "outputs": [],
      "source": [
        "class AR(AbstractModel):\n",
        "    def __init__(self, n_item, n_dim, n_resp, n_rank, p=0.1,\n",
        "                 heads=2, depth=2, batch_size=32, weight_decay=1e-6):\n",
        "        super().__init__()\n",
        "        self.n_dim = n_dim\n",
        "        self.n_item = n_item\n",
        "        self.n_resp = n_resp\n",
        "        self.save_hyperparameters()\n",
        "        \n",
        "        # This means that item=0 will always yield the zero vector\n",
        "        self.item = nn.Embedding(n_item, n_dim, padding_idx=0)\n",
        "        self.resp = nn.Embedding(n_resp, n_dim)\n",
        "        self.reformer = Reformer(dim=n_dim, depth=depth, heads=heads, \n",
        "                                 causal=True)\n",
        "        self.batch_size = batch_size\n",
        "        self.weight_decay = weight_decay\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "    \n",
        "    def forward(self, items, ratng):\n",
        "        item_vec = self.item(items)\n",
        "        resp_vec = self.resp(ratng)\n",
        "        intx_vec = self.dropout(item_vec * resp_vec)\n",
        "        mask = items != 0\n",
        "        user_vec = self.reformer(intx_vec, input_mask=mask)\n",
        "        return user_vec\n",
        "    \n",
        "    def loss(self, user_raw, items, ratg):\n",
        "        # user_vec is (batchsize, window, n_dim)\n",
        "        batchsize, window, n_dim = user_raw.shape\n",
        "        item_raw = self.item(items)\n",
        "        user_bas, user_vec = user_raw[:, :, 0], user_raw[:, :, 1:]\n",
        "        item_bas, item_vec = item_raw[:, :, 0], item_raw[:, :, 1:]\n",
        "        pred = user_bas + item_bas + (user_vec * item_vec).sum(dim=2)\n",
        "        # Ignore ratings that are zero -- zero isn't actually possible from the\n",
        "        # user. Instead zero is empty padding that we should ignore.\n",
        "        mask = ratg != 0\n",
        "        loss_sum = F.mse_loss(pred[mask], ratg[mask] * 1.0, reduction='sum')\n",
        "        loss_mean = loss_sum / (mask.sum() * 1.0)\n",
        "        return loss_mean, {\"mse\": loss_mean}\n",
        "        \n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-4, \n",
        "                                weight_decay=self.weight_decay)\n",
        "\n",
        "    def step(self, batch, batch_nb, prefix='train', add_reg=True):\n",
        "        items, ratng = batch\n",
        "        # Pass in leading arrays, missing the last element\n",
        "        # (hence the [:-1]) for every user that's to  be predicted\n",
        "        user_vec = self.forward(items[:,  :-1], ratng[:, :-1])\n",
        "        # Given previous tokens, predict the next interaction\n",
        "        # hence the [1:] \n",
        "        loss, log = self.loss(user_vec, items[:, 1:],  ratng[:, 1:])\n",
        "        log[f'{prefix}_loss'] = loss\n",
        "        return {f'{prefix}_loss': loss, 'loss':loss, 'log': log}\n",
        "        \n",
        "    def reg(self):\n",
        "        # Regularize via weight decay instead of explicitly\n",
        "        return 0.0, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WahmZNSDtHG1"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.loggers.wandb import WandbLogger\n",
        "\n",
        "n_dim = 48\n",
        "model = AR(n_item, n_dim, n_resp, n_rank, \n",
        "           heads=8, depth=6)\n",
        "logger = WandbLogger(name=\"09_mf\", project=\"simple_mf\")\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=100, logger=logger,\n",
        "                     gpus=1, progress_bar_refresh_rate=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjJaGgk1tHG1"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, train, val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ7iDrCZtHG2"
      },
      "outputs": [],
      "source": [
        "trainer.test(model, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cozzZagMtHG2"
      },
      "outputs": [],
      "source": [
        "results = trainer.test(model)\n",
        "results['avg_test_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqkTb6y7tHG2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "09 Autoregressive MF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}