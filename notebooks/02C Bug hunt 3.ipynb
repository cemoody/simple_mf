{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iA_qC5BAv6w"
   },
   "source": [
    "### Bug Hunt: Data Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the last bug, this bug does not have an explicit error and is extremely difficult to find. \n",
    "\n",
    "Instead, look to the logs! Remember that observations should be randomly sampled. \n",
    "If they are not IID, then your loss curve will have structure. \n",
    "\n",
    "This bug only shows up once you visualize the loss curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_item 3953\n",
      "n_user 6041\n",
      "n_featuers 9994\n",
      "n_occu 21\n",
      "n_rows 1000209\n"
     ]
    }
   ],
   "source": [
    "!python ../src/download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "POjwTTneAv6y",
    "outputId": "b3acebb0-47b2-405c-eb40-5474b7aab5c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4605 2427  154   15]\n",
      " [2156 2170  312   19]\n",
      " [2165 1208  192    7]\n",
      " ...\n",
      " [5686 1077  176   16]\n",
      " [4243  349   35    7]\n",
      " [ 456 1610  147    0]]\n",
      " \n",
      "[[4.]\n",
      " [2.]\n",
      " [4.]\n",
      " ...\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import from_numpy\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import BatchSampler\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "fh = np.load('data/dataset.npz')\n",
    "\n",
    "# We have a bunch of feature columns and last column is the y-target\n",
    "# Note pytorch is finicky about need int64 types\n",
    "train_x = fh['train_x'].astype(np.int64)\n",
    "train_y = fh['train_y']\n",
    "\n",
    "# We've already split into train & test\n",
    "X_test = fh['test_x'].astype(np.int64)\n",
    "Y_test = fh['test_y']\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train_x, train_y)\n",
    "\n",
    "\n",
    "n_user = int(fh['n_user'])\n",
    "n_item = int(fh['n_item'])\n",
    "\n",
    "# columns are user_id, item_id and other features \n",
    "# we won't use the 3rd and 4th columns\n",
    "print(X_train)\n",
    "print(' ')\n",
    "print(Y_train)\n",
    "\n",
    "\n",
    "\n",
    "def dataloader(*arrs, batch_size=1024):\n",
    "    dataset = TensorDataset(*arrs)\n",
    "    arr_size = len(arrs[0])\n",
    "    bs = BatchSampler(SequentialSampler(range(arr_size)),\n",
    "                      batch_size=batch_size, drop_last=False)\n",
    "    return DataLoader(dataset, batch_sampler=bs, shuffle=False)\n",
    " \n",
    "train = dataloader(from_numpy(X_train), from_numpy(Y_train))\n",
    "test = dataloader(from_numpy(X_test), from_numpy(Y_test))\n",
    "val = dataloader(from_numpy(X_val), from_numpy(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstract_model import AbstractModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "def l2_regularize(array):\n",
    "    return torch.sum(array ** 2.0)\n",
    "\n",
    "\n",
    "class MF(AbstractModel):\n",
    "    def __init__(self, n_user, n_item, k=18, c_vector=1.0, c_bias=1.0):\n",
    "        super().__init__()\n",
    "        # These are simple hyperparameters\n",
    "        self.k = k\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.c_vector = c_vector\n",
    "        self.c_bias = c_bias\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # These are learned and fit by PyTorch\n",
    "        self.user = nn.Embedding(n_user, k)\n",
    "        self.item = nn.Embedding(n_item, k)\n",
    "        \n",
    "        # We've added new terms here:\n",
    "        self.bias_user = nn.Embedding(n_user, 1)\n",
    "        self.bias_item = nn.Embedding(n_item, 1)\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # This is the most import function in this script\n",
    "        # These are the user indices, and correspond to \"u\" variable\n",
    "        user_id = inputs[:, 0]\n",
    "        # Item indices, correspond to the \"i\" variable\n",
    "        item_id = inputs[:, 1]\n",
    "        # vector user = p_u\n",
    "        vector_user = self.user(user_id)\n",
    "        # vector item = q_i\n",
    "        vector_item = self.item(item_id)\n",
    "        # this is a dot product & a user-item interaction: p_u * q_i\n",
    "        ui_interaction = torch.sum(vector_user * vector_item)\n",
    "        \n",
    "        # Pull out biases\n",
    "        bias_user = self.bias_user(user_id)\n",
    "        bias_item = self.bias_item(item_id)\n",
    "        biases = (self.bias + bias_user + bias_item)\n",
    "\n",
    "        # Add bias prediction to the interaction prediction\n",
    "        prediction = ui_interaction + biases\n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "        # MSE error between target = R_ui and prediction = p_u * q_i\n",
    "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
    "        return loss_mse, {\"mse\": loss_mse}\n",
    "    \n",
    "    def reg(self):\n",
    "        # Add new regularization to the biases\n",
    "        reg_bias_user =  l2_regularize(self.bias_user.weight) * self.c_bias\n",
    "        reg_bias_item = l2_regularize(self.bias_item.weight) * self.c_bias\n",
    "        # Compute L2 reularization over user (P) and item (Q) matrices\n",
    "        reg_user =  l2_regularize(self.user.weight) * self.c_vector\n",
    "        reg_item = l2_regularize(self.item.weight) * self.c_vector\n",
    "        # Add up the MSE loss + user & item regularization\n",
    "        log = {\"reg_user\": reg_user, \"reg_item\": reg_item,\n",
    "               \"reg_bias_user\": reg_bias_user, \"reg_bias_item\": reg_bias_item}\n",
    "        total = reg_user + reg_item + reg_bias_user + reg_bias_item\n",
    "        return total, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y69Pl4msAv7M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "\n",
    "k = 5\n",
    "c_vector = 1e-5\n",
    "c_bias = 5e-8\n",
    "model = MF(n_user, n_item, k=k, c_bias=c_bias, c_vector=c_vector)\n",
    "\n",
    "# add a logger\n",
    "logger = WandbLogger(name=\"02_mf\", project=\"simple_mf\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100, logger=logger,\n",
    "                     early_stop_callback=True,\n",
    "                     progress_bar_refresh_rate=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msf-moody\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_155405-3g88y3oj\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m02_mf\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sf-moody/simple_mf\" target=\"_blank\">https://wandb.ai/sf-moody/simple_mf</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sf-moody/simple_mf/runs/3g88y3oj\" target=\"_blank\">https://wandb.ai/sf-moody/simple_mf/runs/3g88y3oj</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | user      | Embedding | 30 K  \n",
      "1 | item      | Embedding | 19 K  \n",
      "2 | bias_user | Embedding | 6 K   \n",
      "3 | bias_item | Embedding | 3 K   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:57: UserWarning: Using a target size (torch.Size([1024])) that is different to the input size (torch.Size([1024, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24185174d29e4016b113ad1ee5708842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:57: UserWarning: Using a target size (torch.Size([354])) that is different to the input size (torch.Size([354, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:57: UserWarning: Using a target size (torch.Size([801])) that is different to the input size (torch.Size([801, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n",
      "Epoch 00009: early stopping triggered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "01 Training a simple MF model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
