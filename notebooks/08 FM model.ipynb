{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iA_qC5BAv6w"
   },
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script that downloads and processes the MovieLens data.\n",
    "Uncomment it to run the download & processing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python ../src/download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "POjwTTneAv6y",
    "outputId": "b3acebb0-47b2-405c-eb40-5474b7aab5c2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fh = np.load('data/dataset.npz')\n",
    "# We have a bunch of feature columns and last column is the y-target\n",
    "train_x = fh['train_x'].astype(np.int64)\n",
    "train_y = fh['train_y']\n",
    "\n",
    "test_x = fh['test_x'].astype(np.int64)\n",
    "test_y = fh['test_y']\n",
    "\n",
    "n_user = int(fh['n_user'])\n",
    "n_item = int(fh['n_item'])\n",
    "n_occu = int(fh['n_occu'])\n",
    "n_rank = int(fh['n_ranks'])\n",
    "\n",
    "train_x[:, 1] += n_user\n",
    "train_x[:, 2] += n_user + n_item\n",
    "train_x[:, 3] += n_user + n_item + n_occu\n",
    "test_x[:, 1] += n_user\n",
    "test_x[:, 2] += n_user + n_item\n",
    "test_x[:, 3] += n_user + n_item + n_occu\n",
    "\n",
    "n_feat = n_user + n_item + n_occu + n_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstract_model import AbstractModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def l2_regularize(array):\n",
    "    loss = torch.sum(array ** 2.0)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def index_into(arr, idx):\n",
    "    new_shape = (idx.size()[0], idx.size()[1], arr.size()[1])\n",
    "    return arr[idx.resize(torch.numel(idx.data))].view(new_shape)\n",
    "\n",
    "\n",
    "def factorization_machine(v, x=None):\n",
    "    # Takes an input 2D matrix v of n vectors, each d-dimensional\n",
    "    # produces output that is d-dimensional\n",
    "    # v is (batchsize, n_features, dim)\n",
    "    # x is (batchsize, n_features)\n",
    "    # x functions as a weight array, assumed to be 1 if missing\n",
    "    # Uses Rendle's trick for computing pairs of features in linear time\n",
    "    batchsize = v.size()[0]\n",
    "    n_features = v.size()[1]\n",
    "    n_dim = v.size()[2]\n",
    "    if x is None:\n",
    "        x = Variable(torch.ones(v.size())).to(v.device)\n",
    "    else:\n",
    "        x = x.expand(batchsize, n_features, n_dim)\n",
    "    t0 = (v * x).sum(dim=1)**2.0\n",
    "    t1 = (v**2.0 * x**2.0).sum(dim=1)\n",
    "    return 0.5 * (t0 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "class MF(AbstractModel):\n",
    "    def __init__(self, n_feat, \n",
    "                 k=18, c_feat=1.0, c_bias=1.0, \n",
    "                 batch_size=128):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.n_feat = n_feat\n",
    "        self.feat = nn.Embedding(n_feat, k)\n",
    "        self.bias_feat = nn.Embedding(n_feat, 1)\n",
    "        self.c_feat = c_feat\n",
    "        self.c_bias = c_bias\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        biases = index_into(self.bias_feat.weight, inputs).squeeze().sum(dim=1)\n",
    "        vectrs = index_into(self.feat.weight, inputs)\n",
    "        interx = factorization_machine(vectrs).squeeze().sum(dim=1)\n",
    "        logodds = biases + interx\n",
    "        return logodds \n",
    "\n",
    "    def likelihood(self, prediction, target):\n",
    "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
    "        return loss_mse, {\"mse\": loss_mse}\n",
    "    \n",
    "    def reg(self):\n",
    "        reg_feat = l2_regularize(self.feat.weight) * self.c_feat\n",
    "        log = dict(reg_feat=reg_feat)\n",
    "        return reg_feat, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.logging import WandbLogger\n",
    "\n",
    "\n",
    "k = 8\n",
    "c_bias = 1e-3\n",
    "c_feat = 1e-5\n",
    "model = MF(n_feat,\n",
    "           k=k, c_bias=c_bias, c_feat=c_feat,\n",
    "           batch_size=1024)\n",
    "model.save_data(train_x, train_y, train_x, train_y)\n",
    "\n",
    "# add a logger\n",
    "logger = WandbLogger(name=\"08_mf\", project=\"simple_mf\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100, logger=logger,\n",
    "                     early_stop_callback=True,\n",
    "                     gpus=1, progress_bar_refresh_rate=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JR7UIF0vAv69"
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zebJlH2LAv7D"
   },
   "outputs": [],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8AgnqWgCAv7H"
   },
   "source": [
    "#### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "oLvb4afZAv7F",
    "outputId": "c26239cd-63f2-4337-9a84-79aafbce46ee"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "01 Training a simple MF model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
